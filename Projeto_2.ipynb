{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto 2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ladsong/if697-2020.2-data-science/blob/projeto2/Projeto_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP7bSbbR0eNH"
      },
      "source": [
        "##Preparando o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZrgWPKwwqDA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import gc\n",
        "import warnings\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6U08MfwzZqI",
        "outputId": "0a671231-af06-4cb6-9e6d-1365a86e2dd6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmM_Ob5nzhzR",
        "outputId": "a5e74f67-119d-4658-86bc-0b6e99d11734"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "# /content/gdrive/My Drive/Kaggle é o caminho onde o arquivo kaggle.json está presente do Google Drive\n",
        "#Mudar o diretorio\n",
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPPNFhH6zqyn"
      },
      "source": [
        "##Carregando o dataset e processando os dados\n",
        "No projeto 1, foi adicionado o dump dos dados para que possamos utiliza-los aqui. O objetivo desse projeto é predizer a popularidade de uma música através de suas caracteristicas informadas no subset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950oJnwAzuQa"
      },
      "source": [
        "df = pd.read_csv('project1_output.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDXvjdgL1E3C"
      },
      "source": [
        "Observamos que o dataset é grande e assim decidimos utilizar um subset  com o objetivo de diminuir o tempo de experimentação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAzyCDNI1B2p",
        "outputId": "403a5773-814d-4c49-e61f-ae8b527ea135"
      },
      "source": [
        "\n",
        "df = df[:1000]\n",
        "df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "year                   int64\n",
              "acousticness         float64\n",
              "artists_data          object\n",
              "danceability         float64\n",
              "duration_ms            int64\n",
              "energy               float64\n",
              "explicit               int64\n",
              "id                    object\n",
              "instrumentalness     float64\n",
              "loudness             float64\n",
              "name                  object\n",
              "popularity           float64\n",
              "release_date          object\n",
              "speechiness          float64\n",
              "tempo                float64\n",
              "first_artist          object\n",
              "artists_by_artist     object\n",
              "first_genre           object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PG6pe_RQJk3"
      },
      "source": [
        "Tirando colunas desnecessárias, como `artist_data, id, name, release_date, first_artist, artists_by_artist` e `first_genre,` pois só queremos trabalhar com valores numéricos\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmVGx9hJQW0B"
      },
      "source": [
        "df = df.select_dtypes(exclude=['object'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggg_wtCGQc-w",
        "outputId": "efda2f4f-7d90-4d98-8eb3-5252193bedd9"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['year', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
              "       'explicit', 'instrumentalness', 'loudness', 'popularity', 'speechiness',\n",
              "       'tempo'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U48qY0V8RXrQ"
      },
      "source": [
        "\n",
        "\n",
        "###Escolher coluna para predição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30gxMAGvRe4u"
      },
      "source": [
        "target_col = df['popularity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-zjSp-7SPB-",
        "outputId": "ae4c36e5-1ffd-4460-b161-0195f28e9512"
      },
      "source": [
        "target_col"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.04\n",
              "1      0.02\n",
              "2      0.04\n",
              "3      0.00\n",
              "4      0.01\n",
              "       ... \n",
              "995    0.00\n",
              "996    0.00\n",
              "997    0.00\n",
              "998    0.00\n",
              "999    0.00\n",
              "Name: popularity, Length: 1000, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ6TKxGGSdUq"
      },
      "source": [
        "df = df.drop(columns=['popularity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp4z9GRaS2li"
      },
      "source": [
        "##Separando os dados em teste e predição\n",
        "Para realizacão do treinamento, teste e vaidacão, iremos separa o subset em: \n",
        "\n",
        "*   3/5 dos dados para treinamento\n",
        "*   1/5 dos dados para teste \n",
        "*   1/5 dos dados para validacão\n",
        "\n",
        "Seguindo assim, uma base 60/20/20\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llnzPoPOS8-l"
      },
      "source": [
        "def get_x_data():\n",
        "    # input \n",
        "    train, val, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
        "    \n",
        "    return train, val, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWlYxs_nvjhR"
      },
      "source": [
        "def get_y_data():\n",
        "    # output\n",
        "    train_labels, val_labels, test_labels = (\n",
        "        np.split(\n",
        "            target_col, \n",
        "            [int(.6*len(target_col)), int(.8*len(target_col))])\n",
        "    )\n",
        "    \n",
        "    return train_labels, val_labels, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lu5e9X9vsBw"
      },
      "source": [
        "##Escolher os 4 algoritmos para predição"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYbNEFCzEsBU"
      },
      "source": [
        "Os algoritmos de predicão que iremos usar são:\n",
        "\n",
        "*   Regressão Linear\n",
        "*   Multilayer perceptron\n",
        "*   Random forests\n",
        "*   Gradient boost com lightgbm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh6drbfgHj1I",
        "outputId": "27b97119-435a-4683-d586-5ee43a416478"
      },
      "source": [
        "!pip install mlflow --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.4 MB 58 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 27.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 170 kB 57.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 39.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 37.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25h  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0cVUQd7JL_H",
        "outputId": "b670e9fc-66eb-4d3c-9818-6a729f6416da"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.9.1-py3-none-any.whl (302 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 102 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 143 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 153 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 163 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 174 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 184 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 194 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 204 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 215 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 225 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 235 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 245 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 266 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 276 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 286 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 296 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 302 kB 25.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (5.4.1)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.8.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.22)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.2)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.1.2-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=ce5583930f9674fdda11cc41c652383fe2a3172f2f2bdc274bc583f8c3f3bea5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, cmd2, colorlog, cmaes, cliff, optuna\n",
            "Successfully installed cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-5.0.1 optuna-2.9.1 pbr-5.6.0 pyperclip-1.8.2 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n-LB6i-HaTv"
      },
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import optuna\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import lightgbm\n",
        "from lightgbm import LGBMRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFdO3ZS2Jmyg"
      },
      "source": [
        "#Função de avaliação das metricas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Qm1Z9QJqJI"
      },
      "source": [
        "def eval_metrics(actual, pred):\n",
        "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "    mae = mean_absolute_error(actual, pred)\n",
        "    return rmse, mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnE6KnfvJ1WN",
        "outputId": "096d36f6-1281-4d23-9498-4d8b5d25f28d"
      },
      "source": [
        "mlflow.sklearn.autolog()\n",
        "mlflow.tensorflow.autolog()\n",
        "mlflow.lightgbm.autolog()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/08/16 22:49:00 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of lightgbm. If you encounter errors during autologging, try upgrading / downgrading lightgbm to a supported version, or try upgrading MLflow.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcv8mZ28J8MX"
      },
      "source": [
        "###Regressão Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-NWvytLJ7uY"
      },
      "source": [
        "def linear_regression(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "\n",
        "    # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
        "    with mlflow.start_run(run_name=\"Linear Regression\"):\n",
        "        reg = LinearRegression()\n",
        "        reg.fit(train, train_labels)\n",
        "\n",
        "        predictions = reg.predict(val)\n",
        "\n",
        "        (rmse, mae) = eval_metrics(val_labels, predictions)\n",
        "\n",
        "        # Print out model metrics\n",
        "        print(\"Modelo de regressão linear\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "\n",
        "        # Log mlflow attributes for mlflow UI\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        \n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyu7BWpJKFkd",
        "outputId": "0ffa721e-315b-45cf-b5bd-a78c45e7a78c"
      },
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(linear_regression, n_trials=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:05,292]\u001b[0m A new study created in memory with name: no-name-5f57321a-8bf3-4278-b29f-00705065819f\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Modelo de regressão linear\n",
            "  RMSE: 0.019455898528420473\n",
            "  MAE: 0.017646177370942265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:05,869]\u001b[0m Trial 0 finished with value: 0.019455898528420473 and parameters: {}. Best is trial 0 with value: 0.019455898528420473.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMU8ss6ULFv_"
      },
      "source": [
        "###Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a1ihwwcLHoe"
      },
      "source": [
        "def mlp(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    # hyper-parameters to test\n",
        "    params = {\n",
        "        \"hidden_units\": trial.suggest_int(\"hidden_units\", 3, 15),\n",
        "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n",
        "        \"epochs\": trial.suggest_int(\"epochs\", 10, 50)\n",
        "    }\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "    \n",
        "    # Start an MLflow run\n",
        "    with mlflow.start_run(run_name=\"MLP\"):\n",
        "        normalizer = preprocessing.Normalization(axis=-1)\n",
        "        normalizer.adapt(np.array(train))\n",
        "        \n",
        "        mlp_model = tf.keras.Sequential([\n",
        "            normalizer,\n",
        "            layers.Dense(units=params[\"hidden_units\"]),\n",
        "            layers.Dense(units=params[\"hidden_units\"]),\n",
        "            layers.Dense(units=params[\"hidden_units\"]),\n",
        "            layers.Dense(units=1),\n",
        "        ])\n",
        "\n",
        "        mlp_model.summary()\n",
        "        \n",
        "        mlp_model.compile(\n",
        "            optimizer=tf.optimizers.Adam(learning_rate=params[\"lr\"]),\n",
        "            loss='mean_squared_error'\n",
        "        )\n",
        "\n",
        "        history = mlp_model.fit(\n",
        "            train, train_labels,\n",
        "            validation_data=(test, test_labels),\n",
        "            epochs=params[\"epochs\"]\n",
        "        )\n",
        "        \n",
        "        predictions = mlp_model.predict(val)\n",
        "\n",
        "        (rmse, mae) = eval_metrics(val_labels, predictions)\n",
        "\n",
        "        # Print out model metrics\n",
        "        print(\"MLP model\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "\n",
        "        # Log mlflow attributes for mlflow UI\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        mlflow.log_params(trial.params)\n",
        "        mlflow.set_tags(\n",
        "            {\n",
        "                \"estimator_name\":\"MultiLayerPerceptron\",\n",
        "                \"estimator_class\":\"Keras\"\n",
        "            }\n",
        "        )\n",
        "        #mlflow.tensorflow.log_model(mlp_model, \"model\")\n",
        "        #modelpath = \"./mlflow/freight_value/model-mlp\"\n",
        "        #mlflow.tensorflow.save_model(mlp_model, modelpath)\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMWfjUoYLPpm",
        "outputId": "10f52113-fc54-4067-a3b2-d9e7fbe2f0b0"
      },
      "source": [
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(mlp, n_trials=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:08,086]\u001b[0m A new study created in memory with name: no-name-339bd9e2-3bbd-45ce-ae8e-ba9ed0eee4a4\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 9)                 99        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 10        \n",
            "=================================================================\n",
            "Total params: 310\n",
            "Trainable params: 289\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/36\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 1.9802WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0176s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 18ms/step - loss: 2.5022 - val_loss: 1.7990\n",
            "Epoch 2/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.0585 - val_loss: 1.4871\n",
            "Epoch 3/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6985 - val_loss: 1.2371\n",
            "Epoch 4/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.4199 - val_loss: 1.0355\n",
            "Epoch 5/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1802 - val_loss: 0.8797\n",
            "Epoch 6/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.9928 - val_loss: 0.7484\n",
            "Epoch 7/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.8468 - val_loss: 0.6301\n",
            "Epoch 8/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7105 - val_loss: 0.5351\n",
            "Epoch 9/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5987 - val_loss: 0.4601\n",
            "Epoch 10/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5102 - val_loss: 0.3894\n",
            "Epoch 11/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4327 - val_loss: 0.3306\n",
            "Epoch 12/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3643 - val_loss: 0.2808\n",
            "Epoch 13/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3086 - val_loss: 0.2368\n",
            "Epoch 14/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2593 - val_loss: 0.2017\n",
            "Epoch 15/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2189 - val_loss: 0.1706\n",
            "Epoch 16/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1837 - val_loss: 0.1449\n",
            "Epoch 17/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1551 - val_loss: 0.1222\n",
            "Epoch 18/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1300 - val_loss: 0.1038\n",
            "Epoch 19/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1085 - val_loss: 0.0888\n",
            "Epoch 20/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.0757\n",
            "Epoch 21/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0766 - val_loss: 0.0655\n",
            "Epoch 22/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.0565\n",
            "Epoch 23/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0547 - val_loss: 0.0493\n",
            "Epoch 24/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.0435\n",
            "Epoch 25/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0389\n",
            "Epoch 26/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0351\n",
            "Epoch 27/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.0319\n",
            "Epoch 28/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0294\n",
            "Epoch 29/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0274\n",
            "Epoch 30/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.0256\n",
            "Epoch 31/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0243\n",
            "Epoch 32/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0233\n",
            "Epoch 33/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0223\n",
            "Epoch 34/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0216\n",
            "Epoch 35/36\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0210\n",
            "Epoch 36/36\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0204\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp7u8rpsek/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.09038554344523447\n",
            "  MAE: 0.07365509443853517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:15,216]\u001b[0m Trial 0 finished with value: 0.09038554344523447 and parameters: {'hidden_units': 9, 'lr': 0.00022723168785531795, 'epochs': 36}. Best is trial 0 with value: 0.09038554344523447.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 33        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 82\n",
            "Trainable params: 61\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/32\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 2.6038WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0162s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 18ms/step - loss: 1.9708 - val_loss: 1.1704\n",
            "Epoch 2/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.7932 - val_loss: 1.0640\n",
            "Epoch 3/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.6348 - val_loss: 0.9674\n",
            "Epoch 4/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.4928 - val_loss: 0.8813\n",
            "Epoch 5/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.3650 - val_loss: 0.8038\n",
            "Epoch 6/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2496 - val_loss: 0.7353\n",
            "Epoch 7/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1446 - val_loss: 0.6757\n",
            "Epoch 8/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0546 - val_loss: 0.6192\n",
            "Epoch 9/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.9705 - val_loss: 0.5686\n",
            "Epoch 10/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.8925 - val_loss: 0.5248\n",
            "Epoch 11/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8235 - val_loss: 0.4846\n",
            "Epoch 12/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7621 - val_loss: 0.4474\n",
            "Epoch 13/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7057 - val_loss: 0.4133\n",
            "Epoch 14/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6529 - val_loss: 0.3838\n",
            "Epoch 15/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6055 - val_loss: 0.3578\n",
            "Epoch 16/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5638 - val_loss: 0.3334\n",
            "Epoch 17/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5245 - val_loss: 0.3112\n",
            "Epoch 18/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4893 - val_loss: 0.2900\n",
            "Epoch 19/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4556 - val_loss: 0.2720\n",
            "Epoch 20/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4266 - val_loss: 0.2545\n",
            "Epoch 21/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3991 - val_loss: 0.2393\n",
            "Epoch 22/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3735 - val_loss: 0.2259\n",
            "Epoch 23/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3505 - val_loss: 0.2135\n",
            "Epoch 24/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3298 - val_loss: 0.2022\n",
            "Epoch 25/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3101 - val_loss: 0.1913\n",
            "Epoch 26/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2921 - val_loss: 0.1816\n",
            "Epoch 27/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2753 - val_loss: 0.1733\n",
            "Epoch 28/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2603 - val_loss: 0.1651\n",
            "Epoch 29/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2463 - val_loss: 0.1572\n",
            "Epoch 30/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2333 - val_loss: 0.1501\n",
            "Epoch 31/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2209 - val_loss: 0.1437\n",
            "Epoch 32/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2096 - val_loss: 0.1379\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpb162opge/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.4048236142076068\n",
            "  MAE: 0.24966602096911522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:21,849]\u001b[0m Trial 1 finished with value: 0.4048236142076068 and parameters: {'hidden_units': 3, 'lr': 0.0002388773177567857, 'epochs': 32}. Best is trial 0 with value: 0.09038554344523447.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7)                 77        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 8         \n",
            "=================================================================\n",
            "Total params: 218\n",
            "Trainable params: 197\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/32\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 1.8830WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 2.0696 - val_loss: 1.3900\n",
            "Epoch 2/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.0216 - val_loss: 1.3562\n",
            "Epoch 3/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.9754 - val_loss: 1.3228\n",
            "Epoch 4/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9297 - val_loss: 1.2911\n",
            "Epoch 5/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8853 - val_loss: 1.2597\n",
            "Epoch 6/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8423 - val_loss: 1.2287\n",
            "Epoch 7/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.7998 - val_loss: 1.1980\n",
            "Epoch 8/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7579 - val_loss: 1.1688\n",
            "Epoch 9/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.7168 - val_loss: 1.1403\n",
            "Epoch 10/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.6771 - val_loss: 1.1120\n",
            "Epoch 11/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.6377 - val_loss: 1.0842\n",
            "Epoch 12/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.5988 - val_loss: 1.0577\n",
            "Epoch 13/32\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5612 - val_loss: 1.0307\n",
            "Epoch 14/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.5243 - val_loss: 1.0044\n",
            "Epoch 15/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4881 - val_loss: 0.9785\n",
            "Epoch 16/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4518 - val_loss: 0.9542\n",
            "Epoch 17/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4176 - val_loss: 0.9302\n",
            "Epoch 18/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3830 - val_loss: 0.9066\n",
            "Epoch 19/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.3497 - val_loss: 0.8831\n",
            "Epoch 20/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.3168 - val_loss: 0.8603\n",
            "Epoch 21/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.2849 - val_loss: 0.8377\n",
            "Epoch 22/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2533 - val_loss: 0.8159\n",
            "Epoch 23/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.2234 - val_loss: 0.7941\n",
            "Epoch 24/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1926 - val_loss: 0.7739\n",
            "Epoch 25/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1636 - val_loss: 0.7537\n",
            "Epoch 26/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1348 - val_loss: 0.7341\n",
            "Epoch 27/32\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1065 - val_loss: 0.7152\n",
            "Epoch 28/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0794 - val_loss: 0.6959\n",
            "Epoch 29/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0525 - val_loss: 0.6775\n",
            "Epoch 30/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0263 - val_loss: 0.6592\n",
            "Epoch 31/32\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0002 - val_loss: 0.6419\n",
            "Epoch 32/32\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9751 - val_loss: 0.6248\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp4g9iaube/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.8187105378390828\n",
            "  MAE: 0.6515808433695347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:29,359]\u001b[0m Trial 2 finished with value: 0.8187105378390828 and parameters: {'hidden_units': 7, 'lr': 2.235540960821004e-05, 'epochs': 32}. Best is trial 0 with value: 0.09038554344523447.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 11)                121       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 11)                132       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11)                132       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 418\n",
            "Trainable params: 397\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/33\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 0.5087WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0167s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 0.3930 - val_loss: 0.2475\n",
            "Epoch 2/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2138 - val_loss: 0.1502\n",
            "Epoch 3/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1274 - val_loss: 0.0930\n",
            "Epoch 4/33\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0756 - val_loss: 0.0647\n",
            "Epoch 5/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0485\n",
            "Epoch 6/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.0387\n",
            "Epoch 7/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0328\n",
            "Epoch 8/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0292\n",
            "Epoch 9/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0254\n",
            "Epoch 10/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0236\n",
            "Epoch 11/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0217\n",
            "Epoch 12/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0201\n",
            "Epoch 13/33\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0192\n",
            "Epoch 14/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0183\n",
            "Epoch 15/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0175\n",
            "Epoch 16/33\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0169\n",
            "Epoch 17/33\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0164\n",
            "Epoch 18/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0160\n",
            "Epoch 19/33\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0158\n",
            "Epoch 20/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0154\n",
            "Epoch 21/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0155\n",
            "Epoch 22/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0150\n",
            "Epoch 23/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0152\n",
            "Epoch 24/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0148\n",
            "Epoch 25/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0150\n",
            "Epoch 26/33\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0147\n",
            "Epoch 27/33\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0147\n",
            "Epoch 28/33\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0146\n",
            "Epoch 29/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0146\n",
            "Epoch 30/33\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0148\n",
            "Epoch 31/33\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0144\n",
            "Epoch 32/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0145\n",
            "Epoch 33/33\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0146\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpzvke6t5a/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.021984397209475523\n",
            "  MAE: 0.018555690869060348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:36,576]\u001b[0m Trial 3 finished with value: 0.021984397209475523 and parameters: {'hidden_units': 11, 'lr': 0.00041278450308310504, 'epochs': 33}. Best is trial 3 with value: 0.021984397209475523.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 44        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 110\n",
            "Trainable params: 89\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 0.1328WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0171s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 0.1421 - val_loss: 0.0904\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0941 - val_loss: 0.0616\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0635 - val_loss: 0.0456\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0460 - val_loss: 0.0359\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0355 - val_loss: 0.0305\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0274\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0248 - val_loss: 0.0251\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0233\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0220\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0207\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp_o604v9e/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.08984650748801516\n",
            "  MAE: 0.06587274787214119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:40,703]\u001b[0m Trial 4 finished with value: 0.08984650748801516 and parameters: {'hidden_units': 4, 'lr': 0.0003778885557069947, 'epochs': 10}. Best is trial 3 with value: 0.021984397209475523.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 14)                154       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 15        \n",
            "=================================================================\n",
            "Total params: 610\n",
            "Trainable params: 589\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/14\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 1.8450WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0152s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 0.7470 - val_loss: 0.4640\n",
            "Epoch 2/14\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6630 - val_loss: 0.4159\n",
            "Epoch 3/14\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5921 - val_loss: 0.3715\n",
            "Epoch 4/14\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5330 - val_loss: 0.3308\n",
            "Epoch 5/14\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4793 - val_loss: 0.2941\n",
            "Epoch 6/14\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4272 - val_loss: 0.2648\n",
            "Epoch 7/14\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3849 - val_loss: 0.2375\n",
            "Epoch 8/14\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3455 - val_loss: 0.2145\n",
            "Epoch 9/14\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3119 - val_loss: 0.1917\n",
            "Epoch 10/14\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2786 - val_loss: 0.1716\n",
            "Epoch 11/14\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2492 - val_loss: 0.1545\n",
            "Epoch 12/14\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2257 - val_loss: 0.1368\n",
            "Epoch 13/14\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2000 - val_loss: 0.1223\n",
            "Epoch 14/14\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1787 - val_loss: 0.1093\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpvsfdl3tc/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.3406254129246752\n",
            "  MAE: 0.21183790377900003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:48,106]\u001b[0m Trial 5 finished with value: 0.3406254129246752 and parameters: {'hidden_units': 14, 'lr': 7.866821977429363e-05, 'epochs': 14}. Best is trial 3 with value: 0.021984397209475523.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 15)                165       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 682\n",
            "Trainable params: 661\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/31\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 1.4030WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_train_batch_end` time: 0.0188s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 20ms/step - loss: 1.4268 - val_loss: 0.8721\n",
            "Epoch 2/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3122 - val_loss: 0.8076\n",
            "Epoch 3/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2094 - val_loss: 0.7470\n",
            "Epoch 4/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1150 - val_loss: 0.6943\n",
            "Epoch 5/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0317 - val_loss: 0.6448\n",
            "Epoch 6/31\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9570 - val_loss: 0.5991\n",
            "Epoch 7/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.8856 - val_loss: 0.5608\n",
            "Epoch 8/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.8282 - val_loss: 0.5222\n",
            "Epoch 9/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7663 - val_loss: 0.4926\n",
            "Epoch 10/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7178 - val_loss: 0.4611\n",
            "Epoch 11/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6690 - val_loss: 0.4344\n",
            "Epoch 12/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6277 - val_loss: 0.4074\n",
            "Epoch 13/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5864 - val_loss: 0.3841\n",
            "Epoch 14/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5497 - val_loss: 0.3617\n",
            "Epoch 15/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5158 - val_loss: 0.3433\n",
            "Epoch 16/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4853 - val_loss: 0.3244\n",
            "Epoch 17/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4556 - val_loss: 0.3060\n",
            "Epoch 18/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4291 - val_loss: 0.2899\n",
            "Epoch 19/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4030 - val_loss: 0.2765\n",
            "Epoch 20/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3797 - val_loss: 0.2628\n",
            "Epoch 21/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3584 - val_loss: 0.2486\n",
            "Epoch 22/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3378 - val_loss: 0.2365\n",
            "Epoch 23/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3202 - val_loss: 0.2246\n",
            "Epoch 24/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3021 - val_loss: 0.2137\n",
            "Epoch 25/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2850 - val_loss: 0.2044\n",
            "Epoch 26/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2698 - val_loss: 0.1952\n",
            "Epoch 27/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2564 - val_loss: 0.1855\n",
            "Epoch 28/31\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2420 - val_loss: 0.1776\n",
            "Epoch 29/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2293 - val_loss: 0.1700\n",
            "Epoch 30/31\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2174 - val_loss: 0.1625\n",
            "Epoch 31/31\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2065 - val_loss: 0.1552\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpbissavdg/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.4512702252794352\n",
            "  MAE: 0.30603138742973096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:40:55,509]\u001b[0m Trial 6 finished with value: 0.4512702252794352 and parameters: {'hidden_units': 15, 'lr': 5.091792271058144e-05, 'epochs': 31}. Best is trial 3 with value: 0.021984397209475523.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 15)                165       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 682\n",
            "Trainable params: 661\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/21\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 1.2945WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0131s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 1.0817 - val_loss: 0.4963\n",
            "Epoch 2/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4963 - val_loss: 0.2404\n",
            "Epoch 3/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2220 - val_loss: 0.1292\n",
            "Epoch 4/21\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1151 - val_loss: 0.0709\n",
            "Epoch 5/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0435\n",
            "Epoch 6/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0290\n",
            "Epoch 7/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0217\n",
            "Epoch 8/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0188\n",
            "Epoch 9/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0174\n",
            "Epoch 10/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0166\n",
            "Epoch 11/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0162\n",
            "Epoch 12/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0158\n",
            "Epoch 13/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0156\n",
            "Epoch 14/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0155\n",
            "Epoch 15/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0153\n",
            "Epoch 16/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0151\n",
            "Epoch 17/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0151\n",
            "Epoch 18/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0149\n",
            "Epoch 19/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0150\n",
            "Epoch 20/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0147\n",
            "Epoch 21/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0147\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp9vyd8bp9/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.024214301133278424\n",
            "  MAE: 0.01987426995072747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:41:00,935]\u001b[0m Trial 7 finished with value: 0.024214301133278424 and parameters: {'hidden_units': 15, 'lr': 0.0004983902441307072, 'epochs': 21}. Best is trial 3 with value: 0.021984397209475523.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 14)                154       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 15        \n",
            "=================================================================\n",
            "Total params: 610\n",
            "Trainable params: 589\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/21\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 3.0730WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0157s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 0.9948 - val_loss: 0.3019\n",
            "Epoch 2/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2573 - val_loss: 0.1180\n",
            "Epoch 3/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1043 - val_loss: 0.0558\n",
            "Epoch 4/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0295\n",
            "Epoch 5/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.0201\n",
            "Epoch 6/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0166\n",
            "Epoch 7/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0157\n",
            "Epoch 8/21\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0150\n",
            "Epoch 9/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0150\n",
            "Epoch 10/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0146\n",
            "Epoch 11/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0146\n",
            "Epoch 12/21\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 0.0145\n",
            "Epoch 13/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0145\n",
            "Epoch 14/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0147\n",
            "Epoch 15/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0145\n",
            "Epoch 16/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0146\n",
            "Epoch 17/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0146\n",
            "Epoch 18/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0147\n",
            "Epoch 19/21\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0145\n",
            "Epoch 20/21\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0145\n",
            "Epoch 21/21\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0144\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp75ciyql0/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.02244811951739125\n",
            "  MAE: 0.020529663314763455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:41:06,400]\u001b[0m Trial 8 finished with value: 0.02244811951739125 and parameters: {'hidden_units': 14, 'lr': 0.000993719304677227, 'epochs': 21}. Best is trial 3 with value: 0.021984397209475523.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 14)                154       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 15        \n",
            "=================================================================\n",
            "Total params: 610\n",
            "Trainable params: 589\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 0.6517WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0158s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 0.7459 - val_loss: 0.3865\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4268 - val_loss: 0.2252\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2623 - val_loss: 0.1416\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1595 - val_loss: 0.0989\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1068 - val_loss: 0.0722\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0738 - val_loss: 0.0545\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0519 - val_loss: 0.0438\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0387 - val_loss: 0.0361\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0311\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0236 - val_loss: 0.0276\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0254\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0232\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0216\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0206\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0197\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0190\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0183\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0178\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0174\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0170\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp8h50m1y_/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.05029729734074176\n",
            "  MAE: 0.03915265046181157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:41:13,838]\u001b[0m Trial 9 finished with value: 0.05029729734074176 and parameters: {'hidden_units': 14, 'lr': 0.00024949420936076707, 'epochs': 20}. Best is trial 3 with value: 0.021984397209475523.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM_kbNyrLssM"
      },
      "source": [
        "###Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7NqTLYULt3i"
      },
      "source": [
        "def random_forest(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 5),\n",
        "    }\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "    \n",
        "    with mlflow.start_run(run_name=\"Random Forest\"):\n",
        "        rf = RandomForestRegressor(\n",
        "            max_depth=params[\"max_depth\"],\n",
        "            n_estimators=params[\"n_estimators\"],\n",
        "            min_samples_split=params[\"min_samples_split\"],\n",
        "            random_state=0\n",
        "        )\n",
        "        rf.fit(train, train_labels)\n",
        "        \n",
        "        predictions = rf.predict(val)\n",
        "        \n",
        "        (rmse, mae) = eval_metrics(val_labels, predictions)\n",
        "        \n",
        "        print(\"Random Forest model\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "        \n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        mlflow.log_params(trial.params)\n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdHSTFZeLxrs",
        "outputId": "2dd10f17-bda3-4768-f8d1-dd39351943af"
      },
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(random_forest, n_trials=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:43:53,234]\u001b[0m A new study created in memory with name: no-name-8e7f2a4a-7367-45ce-9839-af0b857f7709\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.032229081407279016\n",
            "  MAE: 0.02020424733275734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:43:54,723]\u001b[0m Trial 0 finished with value: 0.032229081407279016 and parameters: {'n_estimators': 135, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 0 with value: 0.032229081407279016.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.029394081257748273\n",
            "  MAE: 0.018991277859937185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:43:55,872]\u001b[0m Trial 1 finished with value: 0.029394081257748273 and parameters: {'n_estimators': 114, 'max_depth': 4, 'min_samples_split': 4}. Best is trial 1 with value: 0.029394081257748273.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.034467635164383795\n",
            "  MAE: 0.021033791681530634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:43:57,105]\u001b[0m Trial 2 finished with value: 0.034467635164383795 and parameters: {'n_estimators': 85, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 1 with value: 0.029394081257748273.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.032228659727565764\n",
            "  MAE: 0.02026813400731827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:43:58,498]\u001b[0m Trial 3 finished with value: 0.032228659727565764 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 1 with value: 0.029394081257748273.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.026497436782335498\n",
            "  MAE: 0.018502547932306376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:43:59,923]\u001b[0m Trial 4 finished with value: 0.026497436782335498 and parameters: {'n_estimators': 130, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 4 with value: 0.026497436782335498.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.031951959016157834\n",
            "  MAE: 0.019814703948013386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:44:01,084]\u001b[0m Trial 5 finished with value: 0.031951959016157834 and parameters: {'n_estimators': 73, 'max_depth': 7, 'min_samples_split': 4}. Best is trial 4 with value: 0.026497436782335498.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.03285529098610156\n",
            "  MAE: 0.02023804640321958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:44:02,405]\u001b[0m Trial 6 finished with value: 0.03285529098610156 and parameters: {'n_estimators': 112, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 4 with value: 0.026497436782335498.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.03264915341859045\n",
            "  MAE: 0.020654763136422977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:44:03,553]\u001b[0m Trial 7 finished with value: 0.03264915341859045 and parameters: {'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 4 with value: 0.026497436782335498.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.03251603743389072\n",
            "  MAE: 0.02010323987100584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:44:04,603]\u001b[0m Trial 8 finished with value: 0.03251603743389072 and parameters: {'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 4 with value: 0.026497436782335498.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.030847109810172392\n",
            "  MAE: 0.018793560781238106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:44:05,934]\u001b[0m Trial 9 finished with value: 0.030847109810172392 and parameters: {'n_estimators': 124, 'max_depth': 6, 'min_samples_split': 3}. Best is trial 4 with value: 0.026497436782335498.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q5kxu8PMNpw"
      },
      "source": [
        "###Gradient boost com lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegzHTIqMV-n"
      },
      "source": [
        "def gradient_boosting(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 25, 35),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10)\n",
        "    }\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "    \n",
        "    with mlflow.start_run(run_name=\"Gradient Boosting\"):\n",
        "#         model = LGBMRegressor(\n",
        "#             max_depth=params[\"max_depth\"],\n",
        "#             n_estimators=params[\"n_estimators\"],\n",
        "#             num_leaves=params[\"num_leaves\"],\n",
        "#         )\n",
        "        model = XGBRegressor(\n",
        "            max_depth=params[\"max_depth\"],\n",
        "            n_estimators=params[\"n_estimators\"],\n",
        "        )\n",
        "        model.fit(train, train_labels)\n",
        "        \n",
        "        predictions = model.predict(test)\n",
        "        print('Prediction: %.3f' % predictions[0])\n",
        "        \n",
        "        (rmse, mae) = eval_metrics(val_labels, predictions)\n",
        "\n",
        "        print(\"LGBM model\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "\n",
        "        # Log mlflow attributes for mlflow UI\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        mlflow.log_params(trial.params)\n",
        "        mlflow.set_tags(\n",
        "            {\n",
        "                \"estimator_class\":\"LightGBM\",\n",
        "                \"estimator_name\":\"Gradient Boosting\"\n",
        "            }\n",
        "        )\n",
        "        mlflow.sklearn.log_model(model, \"model\")\n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MA5E8HHMbRd",
        "outputId": "b3b271ff-c626-451c-ea39-2ffa3e07b906"
      },
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(gradient_boosting, n_trials=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:07,561]\u001b[0m A new study created in memory with name: no-name-5f41e926-5ce7-4675-92d0-b73e68a73a51\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.017\n",
            "LGBM model\n",
            "  RMSE: 0.03993479922439491\n",
            "  MAE: 0.02109046509861946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:08,128]\u001b[0m Trial 0 finished with value: 0.03993479922439491 and parameters: {'n_estimators': 68, 'num_leaves': 34, 'max_depth': 6}. Best is trial 0 with value: 0.03993479922439491.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.006\n",
            "LGBM model\n",
            "  RMSE: 0.03989644219429306\n",
            "  MAE: 0.022985045850276952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:08,801]\u001b[0m Trial 1 finished with value: 0.03989644219429306 and parameters: {'n_estimators': 129, 'num_leaves': 35, 'max_depth': 5}. Best is trial 1 with value: 0.03989644219429306.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.009\n",
            "LGBM model\n",
            "  RMSE: 0.034612421497536086\n",
            "  MAE: 0.021461135834455494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:09,484]\u001b[0m Trial 2 finished with value: 0.034612421497536086 and parameters: {'n_estimators': 57, 'num_leaves': 32, 'max_depth': 5}. Best is trial 2 with value: 0.034612421497536086.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.015\n",
            "LGBM model\n",
            "  RMSE: 0.04208068009638963\n",
            "  MAE: 0.02178560203313827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:10,274]\u001b[0m Trial 3 finished with value: 0.04208068009638963 and parameters: {'n_estimators': 121, 'num_leaves': 32, 'max_depth': 6}. Best is trial 2 with value: 0.034612421497536086.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.003\n",
            "LGBM model\n",
            "  RMSE: 0.0401988941800656\n",
            "  MAE: 0.02306955581903457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:10,968]\u001b[0m Trial 4 finished with value: 0.0401988941800656 and parameters: {'n_estimators': 140, 'num_leaves': 33, 'max_depth': 4}. Best is trial 2 with value: 0.034612421497536086.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.011\n",
            "LGBM model\n",
            "  RMSE: 0.027320911839342425\n",
            "  MAE: 0.018835345554351807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:11,571]\u001b[0m Trial 5 finished with value: 0.027320911839342425 and parameters: {'n_estimators': 80, 'num_leaves': 35, 'max_depth': 3}. Best is trial 5 with value: 0.027320911839342425.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.006\n",
            "LGBM model\n",
            "  RMSE: 0.030874716303845952\n",
            "  MAE: 0.01969502604007721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:12,327]\u001b[0m Trial 6 finished with value: 0.030874716303845952 and parameters: {'n_estimators': 115, 'num_leaves': 33, 'max_depth': 3}. Best is trial 5 with value: 0.027320911839342425.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.014\n",
            "LGBM model\n",
            "  RMSE: 0.039269274523501846\n",
            "  MAE: 0.020337877917289734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:13,040]\u001b[0m Trial 7 finished with value: 0.039269274523501846 and parameters: {'n_estimators': 84, 'num_leaves': 31, 'max_depth': 8}. Best is trial 5 with value: 0.027320911839342425.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.023\n",
            "LGBM model\n",
            "  RMSE: 0.03886160671203333\n",
            "  MAE: 0.02232185280323028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:13,693]\u001b[0m Trial 8 finished with value: 0.03886160671203333 and parameters: {'n_estimators': 51, 'num_leaves': 25, 'max_depth': 6}. Best is trial 5 with value: 0.027320911839342425.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:57:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.015\n",
            "LGBM model\n",
            "  RMSE: 0.04136983743460978\n",
            "  MAE: 0.021324082970619197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:57:14,517]\u001b[0m Trial 9 finished with value: 0.04136983743460978 and parameters: {'n_estimators': 93, 'num_leaves': 35, 'max_depth': 6}. Best is trial 5 with value: 0.027320911839342425.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}