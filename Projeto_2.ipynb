{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcATtr6KEmcS8aLpqOGHwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ladsong/if697-2020.2-data-science/blob/projeto2/Projeto_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP7bSbbR0eNH"
      },
      "source": [
        "##Preparando o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZrgWPKwwqDA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import gc\n",
        "import warnings\n",
        "import sys"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6U08MfwzZqI",
        "outputId": "0a671231-af06-4cb6-9e6d-1365a86e2dd6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmM_Ob5nzhzR",
        "outputId": "a5e74f67-119d-4658-86bc-0b6e99d11734"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "# /content/gdrive/My Drive/Kaggle é o caminho onde o arquivo kaggle.json está presente do Google Drive\n",
        "#Mudar o diretorio\n",
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPPNFhH6zqyn"
      },
      "source": [
        "##Carregando o dataset e processando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950oJnwAzuQa"
      },
      "source": [
        "df = pd.read_csv('project1_output.csv')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDXvjdgL1E3C"
      },
      "source": [
        "Vamos utilizar um subset do nosso dataset para diminuir o tempo de experimentação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAzyCDNI1B2p",
        "outputId": "403a5773-814d-4c49-e61f-ae8b527ea135"
      },
      "source": [
        "\n",
        "df = df[:1000]\n",
        "df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
        "df.dtypes"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "year                   int64\n",
              "acousticness         float64\n",
              "artists_data          object\n",
              "danceability         float64\n",
              "duration_ms            int64\n",
              "energy               float64\n",
              "explicit               int64\n",
              "id                    object\n",
              "instrumentalness     float64\n",
              "loudness             float64\n",
              "name                  object\n",
              "popularity           float64\n",
              "release_date          object\n",
              "speechiness          float64\n",
              "tempo                float64\n",
              "first_artist          object\n",
              "artists_by_artist     object\n",
              "first_genre           object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PG6pe_RQJk3"
      },
      "source": [
        "Tirando colunas desnecessárias, pois só queremos trabalhar com valores numéricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmVGx9hJQW0B"
      },
      "source": [
        "df = df.select_dtypes(exclude=['object'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggg_wtCGQc-w",
        "outputId": "efda2f4f-7d90-4d98-8eb3-5252193bedd9"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['year', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
              "       'explicit', 'instrumentalness', 'loudness', 'popularity', 'speechiness',\n",
              "       'tempo'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U48qY0V8RXrQ"
      },
      "source": [
        "\n",
        "\n",
        "####Escolher coluna para predição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30gxMAGvRe4u"
      },
      "source": [
        "target_col = df['popularity']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-zjSp-7SPB-",
        "outputId": "ae4c36e5-1ffd-4460-b161-0195f28e9512"
      },
      "source": [
        "target_col"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.04\n",
              "1      0.02\n",
              "2      0.04\n",
              "3      0.00\n",
              "4      0.01\n",
              "       ... \n",
              "995    0.00\n",
              "996    0.00\n",
              "997    0.00\n",
              "998    0.00\n",
              "999    0.00\n",
              "Name: popularity, Length: 1000, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ6TKxGGSdUq"
      },
      "source": [
        "df = df.drop(columns=['popularity'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp4z9GRaS2li"
      },
      "source": [
        "##Separando os dados em teste e predição"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFURkxzHS948"
      },
      "source": [
        "Usando uma base 60/20/20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llnzPoPOS8-l"
      },
      "source": [
        "def get_x_data():\n",
        "    # input \n",
        "    train, val, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
        "    \n",
        "    return train, val, test"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWlYxs_nvjhR"
      },
      "source": [
        "def get_y_data():\n",
        "    # output\n",
        "    train_labels, val_labels, test_labels = (\n",
        "        np.split(\n",
        "            target_col, \n",
        "            [int(.6*len(target_col)), int(.8*len(target_col))])\n",
        "    )\n",
        "    \n",
        "    return train_labels, val_labels, test_labels"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lu5e9X9vsBw"
      },
      "source": [
        "##Escolher os 4 algoritmos para predição"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYbNEFCzEsBU"
      },
      "source": [
        "Vamos usar:\n",
        "\n",
        "\n",
        "\n",
        "*   Regressão Linear\n",
        "*   Multilayer perceptron\n",
        "*   random forests\n",
        "*   Gradient boost com lightgbm\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh6drbfgHj1I",
        "outputId": "27b97119-435a-4683-d586-5ee43a416478"
      },
      "source": [
        "!pip install mlflow --quiet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.4 MB 58 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 27.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 170 kB 57.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 39.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 37.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25h  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0cVUQd7JL_H",
        "outputId": "b670e9fc-66eb-4d3c-9818-6a729f6416da"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.9.1-py3-none-any.whl (302 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 102 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 143 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 153 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 163 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 174 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 184 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 194 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 204 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 215 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 225 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 235 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 245 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 266 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 276 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 286 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 296 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 302 kB 25.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (5.4.1)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.8.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.22)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.2)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.1.2-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=ce5583930f9674fdda11cc41c652383fe2a3172f2f2bdc274bc583f8c3f3bea5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, cmd2, colorlog, cmaes, cliff, optuna\n",
            "Successfully installed cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-5.0.1 optuna-2.9.1 pbr-5.6.0 pyperclip-1.8.2 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n-LB6i-HaTv"
      },
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import optuna\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import lightgbm\n",
        "from lightgbm import LGBMRegressor"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFdO3ZS2Jmyg"
      },
      "source": [
        "Função de avaliação das metricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Qm1Z9QJqJI"
      },
      "source": [
        "def eval_metrics(actual, pred):\n",
        "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "    mae = mean_absolute_error(actual, pred)\n",
        "    r2 = r2_score(actual, pred)\n",
        "    return rmse, mae, r2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnE6KnfvJ1WN",
        "outputId": "096d36f6-1281-4d23-9498-4d8b5d25f28d"
      },
      "source": [
        "mlflow.sklearn.autolog()\n",
        "mlflow.tensorflow.autolog()\n",
        "mlflow.lightgbm.autolog()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/08/16 22:49:00 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of lightgbm. If you encounter errors during autologging, try upgrading / downgrading lightgbm to a supported version, or try upgrading MLflow.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcv8mZ28J8MX"
      },
      "source": [
        "###Regressão Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-NWvytLJ7uY"
      },
      "source": [
        "def linear_regression(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "\n",
        "    # Start an MLflow run; the \"with\" keyword ensures we'll close the run even if this cell crashes\n",
        "    with mlflow.start_run(run_name=\"Linear Regression\"):\n",
        "        reg = LinearRegression()\n",
        "        reg.fit(train, train_labels)\n",
        "\n",
        "        predictions = reg.predict(val)\n",
        "\n",
        "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
        "\n",
        "        # Print out model metrics\n",
        "        print(\"Modelo de regressão linear\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "        print(\"  R2: %s\" % r2)\n",
        "\n",
        "        # Log mlflow attributes for mlflow UI\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"r2\", r2)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        \n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyu7BWpJKFkd",
        "outputId": "973fe4aa-b1a7-4043-895c-c25bec10feb2"
      },
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(linear_regression, n_trials=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:53:35,524]\u001b[0m A new study created in memory with name: no-name-7934c31b-d81f-4a4c-9736-23f6547d04d0\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Modelo de regressão linear\n",
            "  RMSE: 0.019455898528420473\n",
            "  MAE: 0.017646177370942265\n",
            "  R2: -57.801085444379645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:53:36,137]\u001b[0m Trial 0 finished with value: 0.019455898528420473 and parameters: {}. Best is trial 0 with value: 0.019455898528420473.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMU8ss6ULFv_"
      },
      "source": [
        "Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a1ihwwcLHoe"
      },
      "source": [
        "def mlp(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    # hyper-parameters to test\n",
        "    params = {\n",
        "        \"hidden_units\": trial.suggest_int(\"hidden_units\", 3, 15),\n",
        "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n",
        "        \"epochs\": trial.suggest_int(\"epochs\", 10, 50)\n",
        "    }\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "    \n",
        "    # Start an MLflow run\n",
        "    with mlflow.start_run(run_name=\"MLP\"):\n",
        "        normalizer = preprocessing.Normalization(axis=-1)\n",
        "        normalizer.adapt(np.array(train))\n",
        "        \n",
        "        mlp_model = tf.keras.Sequential([\n",
        "            normalizer,\n",
        "            layers.Dense(units=params[\"hidden_units\"]),\n",
        "            layers.Dense(units=params[\"hidden_units\"]),\n",
        "            layers.Dense(units=params[\"hidden_units\"]),\n",
        "            layers.Dense(units=1),\n",
        "        ])\n",
        "\n",
        "        mlp_model.summary()\n",
        "        \n",
        "        mlp_model.compile(\n",
        "            optimizer=tf.optimizers.Adam(learning_rate=params[\"lr\"]),\n",
        "            loss='mean_squared_error'\n",
        "        )\n",
        "\n",
        "        history = mlp_model.fit(\n",
        "            train, train_labels,\n",
        "            validation_data=(test, test_labels),\n",
        "            epochs=params[\"epochs\"]\n",
        "        )\n",
        "        \n",
        "        predictions = mlp_model.predict(val)\n",
        "\n",
        "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
        "\n",
        "        # Print out model metrics\n",
        "        print(\"MLP model\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "        print(\"  R2: %s\" % r2)\n",
        "\n",
        "        # Log mlflow attributes for mlflow UI\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"r2\", r2)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        mlflow.log_params(trial.params)\n",
        "        mlflow.set_tags(\n",
        "            {\n",
        "                \"estimator_name\":\"MultiLayerPerceptron\",\n",
        "                \"estimator_class\":\"Keras\"\n",
        "            }\n",
        "        )\n",
        "        #mlflow.tensorflow.log_model(mlp_model, \"model\")\n",
        "        #modelpath = \"./mlflow/freight_value/model-mlp\"\n",
        "        #mlflow.tensorflow.save_model(mlp_model, modelpath)\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMWfjUoYLPpm",
        "outputId": "952bb756-53a8-4c6f-b9f6-62e7bb8efc42"
      },
      "source": [
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(mlp, n_trials=10)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:55:09,963]\u001b[0m A new study created in memory with name: no-name-d38c4de0-67eb-4b48-96a1-d921d304a6c5\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7)                 77        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 8         \n",
            "=================================================================\n",
            "Total params: 218\n",
            "Trainable params: 197\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 3.8614 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0145s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 18ms/step - loss: 2.7717 - val_loss: 1.8166\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.4721 - val_loss: 1.6283\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.2124 - val_loss: 1.4612\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.9810 - val_loss: 1.3151\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.7811 - val_loss: 1.1859\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.6065 - val_loss: 1.0730\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.4494 - val_loss: 0.9770\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.3154 - val_loss: 0.8890\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1936 - val_loss: 0.8137\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0894 - val_loss: 0.7464\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.9968 - val_loss: 0.6850\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9122 - val_loss: 0.6313\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.8379 - val_loss: 0.5830\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7708 - val_loss: 0.5400\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7112 - val_loss: 0.5000\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6560 - val_loss: 0.4641\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6075 - val_loss: 0.4315\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5624 - val_loss: 0.4018\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5230 - val_loss: 0.3737\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4846 - val_loss: 0.3491\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp5l7ls5b7/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.6354928533006559\n",
            "  MAE: 0.49639060685550795\n",
            "  R2: -62733.16180135285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:55:17,696]\u001b[0m Trial 0 finished with value: 0.6354928533006559 and parameters: {'hidden_units': 7, 'lr': 0.00011080699654335682, 'epochs': 20}. Best is trial 0 with value: 0.6354928533006559.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 12)                132       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 478\n",
            "Trainable params: 457\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 0.6378WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0112s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 0.8488 - val_loss: 0.5878\n",
            "Epoch 2/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8320 - val_loss: 0.5751\n",
            "Epoch 3/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8150 - val_loss: 0.5634\n",
            "Epoch 4/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7995 - val_loss: 0.5516\n",
            "Epoch 5/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7835 - val_loss: 0.5403\n",
            "Epoch 6/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7688 - val_loss: 0.5284\n",
            "Epoch 7/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7535 - val_loss: 0.5179\n",
            "Epoch 8/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7392 - val_loss: 0.5076\n",
            "Epoch 9/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7252 - val_loss: 0.4977\n",
            "Epoch 10/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7118 - val_loss: 0.4874\n",
            "Epoch 11/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6983 - val_loss: 0.4781\n",
            "Epoch 12/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6854 - val_loss: 0.4689\n",
            "Epoch 13/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6725 - val_loss: 0.4602\n",
            "Epoch 14/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6601 - val_loss: 0.4519\n",
            "Epoch 15/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6484 - val_loss: 0.4429\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpae792_dn/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.6770997652117401\n",
            "  MAE: 0.5225787954472471\n",
            "  R2: -71216.72303686113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:55:22,657]\u001b[0m Trial 1 finished with value: 0.6770997652117401 and parameters: {'hidden_units': 12, 'lr': 1.7116700104715165e-05, 'epochs': 15}. Best is trial 0 with value: 0.6354928533006559.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 142\n",
            "Trainable params: 121\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/19\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 4.8166WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0133s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 3.3499 - val_loss: 2.6608\n",
            "Epoch 2/19\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.2372 - val_loss: 2.5750\n",
            "Epoch 3/19\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.1296 - val_loss: 2.4919\n",
            "Epoch 4/19\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.0234 - val_loss: 2.4110\n",
            "Epoch 5/19\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9183 - val_loss: 2.3350\n",
            "Epoch 6/19\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.8221 - val_loss: 2.2567\n",
            "Epoch 7/19\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.7255 - val_loss: 2.1826\n",
            "Epoch 8/19\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.6332 - val_loss: 2.1123\n",
            "Epoch 9/19\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.5446 - val_loss: 2.0432\n",
            "Epoch 10/19\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.4561 - val_loss: 1.9783\n",
            "Epoch 11/19\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.3731 - val_loss: 1.9134\n",
            "Epoch 12/19\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2907 - val_loss: 1.8525\n",
            "Epoch 13/19\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.2117 - val_loss: 1.7925\n",
            "Epoch 14/19\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1380 - val_loss: 1.7313\n",
            "Epoch 15/19\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 2.0637 - val_loss: 1.6735\n",
            "Epoch 16/19\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.9911 - val_loss: 1.6181\n",
            "Epoch 17/19\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.9192 - val_loss: 1.5671\n",
            "Epoch 18/19\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.8547 - val_loss: 1.5141\n",
            "Epoch 19/19\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.7882 - val_loss: 1.4652\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpg3e7gcno/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 1.0750600412453877\n",
            "  MAE: 0.8584585461288691\n",
            "  R2: -179533.61627689863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:55:30,025]\u001b[0m Trial 2 finished with value: 1.0750600412453877 and parameters: {'hidden_units': 5, 'lr': 6.35797489862511e-05, 'epochs': 19}. Best is trial 0 with value: 0.6354928533006559.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 142\n",
            "Trainable params: 121\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/43\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 3.7774WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0153s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 3.3331 - val_loss: 2.8227\n",
            "Epoch 2/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 3.0363 - val_loss: 2.5835\n",
            "Epoch 3/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.7753 - val_loss: 2.3597\n",
            "Epoch 4/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.5351 - val_loss: 2.1541\n",
            "Epoch 5/43\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.3142 - val_loss: 1.9746\n",
            "Epoch 6/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 2.1197 - val_loss: 1.8096\n",
            "Epoch 7/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.9437 - val_loss: 1.6588\n",
            "Epoch 8/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.7825 - val_loss: 1.5233\n",
            "Epoch 9/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.6367 - val_loss: 1.4004\n",
            "Epoch 10/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.5047 - val_loss: 1.2877\n",
            "Epoch 11/43\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3839 - val_loss: 1.1860\n",
            "Epoch 12/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.2744 - val_loss: 1.0929\n",
            "Epoch 13/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1738 - val_loss: 1.0092\n",
            "Epoch 14/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0842 - val_loss: 0.9293\n",
            "Epoch 15/43\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.9989 - val_loss: 0.8587\n",
            "Epoch 16/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.9230 - val_loss: 0.7925\n",
            "Epoch 17/43\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.8528 - val_loss: 0.7331\n",
            "Epoch 18/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7888 - val_loss: 0.6779\n",
            "Epoch 19/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.7304 - val_loss: 0.6265\n",
            "Epoch 20/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6750 - val_loss: 0.5812\n",
            "Epoch 21/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6267 - val_loss: 0.5375\n",
            "Epoch 22/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5803 - val_loss: 0.4980\n",
            "Epoch 23/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5380 - val_loss: 0.4618\n",
            "Epoch 24/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4995 - val_loss: 0.4278\n",
            "Epoch 25/43\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4633 - val_loss: 0.3971\n",
            "Epoch 26/43\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4299 - val_loss: 0.3691\n",
            "Epoch 27/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3995 - val_loss: 0.3430\n",
            "Epoch 28/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3715 - val_loss: 0.3184\n",
            "Epoch 29/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3453 - val_loss: 0.2955\n",
            "Epoch 30/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3212 - val_loss: 0.2744\n",
            "Epoch 31/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2991 - val_loss: 0.2549\n",
            "Epoch 32/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2782 - val_loss: 0.2375\n",
            "Epoch 33/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2592 - val_loss: 0.2216\n",
            "Epoch 34/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2420 - val_loss: 0.2062\n",
            "Epoch 35/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2255 - val_loss: 0.1924\n",
            "Epoch 36/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2106 - val_loss: 0.1793\n",
            "Epoch 37/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1965 - val_loss: 0.1674\n",
            "Epoch 38/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1836 - val_loss: 0.1564\n",
            "Epoch 39/43\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1717 - val_loss: 0.1462\n",
            "Epoch 40/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1607 - val_loss: 0.1366\n",
            "Epoch 41/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1502 - val_loss: 0.1281\n",
            "Epoch 42/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1407 - val_loss: 0.1201\n",
            "Epoch 43/43\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1320 - val_loss: 0.1126\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpzvmimigo/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.3263431109377179\n",
            "  MAE: 0.2736813705891371\n",
            "  R2: -16542.66230004003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:55:37,413]\u001b[0m Trial 3 finished with value: 0.3263431109377179 and parameters: {'hidden_units': 5, 'lr': 0.00014499786705027954, 'epochs': 43}. Best is trial 3 with value: 0.3263431109377179.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 12)                132       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 478\n",
            "Trainable params: 457\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/22\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 1.0526WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0164s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 18ms/step - loss: 1.3819 - val_loss: 0.9491\n",
            "Epoch 2/22\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3609 - val_loss: 0.9360\n",
            "Epoch 3/22\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3407 - val_loss: 0.9228\n",
            "Epoch 4/22\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3212 - val_loss: 0.9095\n",
            "Epoch 5/22\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.3025 - val_loss: 0.8966\n",
            "Epoch 6/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.2821 - val_loss: 0.8843\n",
            "Epoch 7/22\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2638 - val_loss: 0.8721\n",
            "Epoch 8/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.2452 - val_loss: 0.8599\n",
            "Epoch 9/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.2264 - val_loss: 0.8483\n",
            "Epoch 10/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.2085 - val_loss: 0.8366\n",
            "Epoch 11/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1919 - val_loss: 0.8250\n",
            "Epoch 12/22\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1737 - val_loss: 0.8136\n",
            "Epoch 13/22\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.1571 - val_loss: 0.8025\n",
            "Epoch 14/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1407 - val_loss: 0.7917\n",
            "Epoch 15/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1248 - val_loss: 0.7810\n",
            "Epoch 16/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.1081 - val_loss: 0.7709\n",
            "Epoch 17/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0933 - val_loss: 0.7601\n",
            "Epoch 18/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0771 - val_loss: 0.7501\n",
            "Epoch 19/22\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0625 - val_loss: 0.7400\n",
            "Epoch 20/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0472 - val_loss: 0.7304\n",
            "Epoch 21/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0327 - val_loss: 0.7207\n",
            "Epoch 22/22\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.0188 - val_loss: 0.7111\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpsyzuwmai/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.8929967377825184\n",
            "  MAE: 0.6436392416670685\n",
            "  R2: -123873.6677577041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:55:44,699]\u001b[0m Trial 4 finished with value: 0.8929967377825184 and parameters: {'hidden_units': 12, 'lr': 1.2784426458828901e-05, 'epochs': 22}. Best is trial 3 with value: 0.3263431109377179.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 66        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 178\n",
            "Trainable params: 157\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/34\n",
            " 3/19 [===>..........................] - ETA: 1s - loss: 1.1533WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0203s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 20ms/step - loss: 1.1578 - val_loss: 0.8248\n",
            "Epoch 2/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.8293 - val_loss: 0.5983\n",
            "Epoch 3/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.6004 - val_loss: 0.4427\n",
            "Epoch 4/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4514 - val_loss: 0.3288\n",
            "Epoch 5/34\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3339 - val_loss: 0.2519\n",
            "Epoch 6/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2544 - val_loss: 0.1947\n",
            "Epoch 7/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1945 - val_loss: 0.1495\n",
            "Epoch 8/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1485 - val_loss: 0.1166\n",
            "Epoch 9/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1142 - val_loss: 0.0908\n",
            "Epoch 10/34\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0877 - val_loss: 0.0727\n",
            "Epoch 11/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0584\n",
            "Epoch 12/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0472\n",
            "Epoch 13/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0392\n",
            "Epoch 14/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0333\n",
            "Epoch 15/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0288\n",
            "Epoch 16/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0257\n",
            "Epoch 17/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0233\n",
            "Epoch 18/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0218\n",
            "Epoch 19/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0203\n",
            "Epoch 20/34\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0192\n",
            "Epoch 21/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0186\n",
            "Epoch 22/34\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0181\n",
            "Epoch 23/34\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0177\n",
            "Epoch 24/34\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0173\n",
            "Epoch 25/34\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0171\n",
            "Epoch 26/34\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0167\n",
            "Epoch 27/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0167\n",
            "Epoch 28/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0164\n",
            "Epoch 29/34\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0163\n",
            "Epoch 30/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0162\n",
            "Epoch 31/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0160\n",
            "Epoch 32/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0159\n",
            "Epoch 33/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0159\n",
            "Epoch 34/34\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0156\n",
            "INFO:tensorflow:Assets written to: /tmp/tmphoyfrdf8/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.04429884298920463\n",
            "  MAE: 0.03590494533802849\n",
            "  R2: -303.8368916787891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:55:52,108]\u001b[0m Trial 5 finished with value: 0.04429884298920463 and parameters: {'hidden_units': 6, 'lr': 0.0006057066053097142, 'epochs': 34}. Best is trial 5 with value: 0.04429884298920463.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 15)                165       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 682\n",
            "Trainable params: 661\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 0.1348WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0146s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 0.0902 - val_loss: 0.0249\n",
            "Epoch 2/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0181\n",
            "Epoch 3/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0167\n",
            "Epoch 4/15\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0159\n",
            "Epoch 5/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0155\n",
            "Epoch 6/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0153\n",
            "Epoch 7/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0155\n",
            "Epoch 8/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0146\n",
            "Epoch 9/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0146\n",
            "Epoch 10/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0145\n",
            "Epoch 11/15\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0145\n",
            "Epoch 12/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0148\n",
            "Epoch 13/15\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0148\n",
            "Epoch 14/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0149\n",
            "Epoch 15/15\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0144\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp_weay68o/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.01909312589403764\n",
            "  MAE: 0.017703802173445\n",
            "  R2: -55.62873109212749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:55:59,558]\u001b[0m Trial 6 finished with value: 0.01909312589403764 and parameters: {'hidden_units': 15, 'lr': 0.0005216927434366552, 'epochs': 15}. Best is trial 6 with value: 0.01909312589403764.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 12)                132       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 478\n",
            "Trainable params: 457\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/49\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 0.4616WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0136s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 0.4200 - val_loss: 0.3044\n",
            "Epoch 2/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3088 - val_loss: 0.2338\n",
            "Epoch 3/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2337 - val_loss: 0.1837\n",
            "Epoch 4/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1823 - val_loss: 0.1472\n",
            "Epoch 5/49\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1432 - val_loss: 0.1208\n",
            "Epoch 6/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1145 - val_loss: 0.0994\n",
            "Epoch 7/49\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0924 - val_loss: 0.0836\n",
            "Epoch 8/49\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0744 - val_loss: 0.0705\n",
            "Epoch 9/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0602\n",
            "Epoch 10/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0514\n",
            "Epoch 11/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0445\n",
            "Epoch 12/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0384\n",
            "Epoch 13/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0338\n",
            "Epoch 14/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0304\n",
            "Epoch 15/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0273\n",
            "Epoch 16/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0246\n",
            "Epoch 17/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0229\n",
            "Epoch 18/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0213\n",
            "Epoch 19/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0201\n",
            "Epoch 20/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0191\n",
            "Epoch 21/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0181\n",
            "Epoch 22/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0176\n",
            "Epoch 23/49\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0170\n",
            "Epoch 24/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0167\n",
            "Epoch 25/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0162\n",
            "Epoch 26/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0161\n",
            "Epoch 27/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0157\n",
            "Epoch 28/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0155\n",
            "Epoch 29/49\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0153\n",
            "Epoch 30/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0153\n",
            "Epoch 31/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0151\n",
            "Epoch 32/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0150\n",
            "Epoch 33/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0147\n",
            "Epoch 34/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0150\n",
            "Epoch 35/49\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0149\n",
            "Epoch 36/49\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0146\n",
            "Epoch 37/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0145\n",
            "Epoch 38/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0148\n",
            "Epoch 39/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0146\n",
            "Epoch 40/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0146\n",
            "Epoch 41/49\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0145\n",
            "Epoch 42/49\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0146\n",
            "Epoch 43/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0145\n",
            "Epoch 44/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0144\n",
            "Epoch 45/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0145\n",
            "Epoch 46/49\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0145\n",
            "Epoch 47/49\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0144\n",
            "Epoch 48/49\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0144\n",
            "Epoch 49/49\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 0.0145\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp3aeo8k5a/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.019510929578675073\n",
            "  MAE: 0.017315092339762486\n",
            "  R2: -58.1341938678086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:56:07,624]\u001b[0m Trial 7 finished with value: 0.019510929578675073 and parameters: {'hidden_units': 12, 'lr': 0.00019891917216085112, 'epochs': 49}. Best is trial 6 with value: 0.01909312589403764.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 11)                121       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 11)                132       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11)                132       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 418\n",
            "Trainable params: 397\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/24\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 0.7692WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0166s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 0.7211 - val_loss: 0.4677\n",
            "Epoch 2/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4756 - val_loss: 0.3058\n",
            "Epoch 3/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3082 - val_loss: 0.2178\n",
            "Epoch 4/24\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2190 - val_loss: 0.1562\n",
            "Epoch 5/24\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1190\n",
            "Epoch 6/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1140 - val_loss: 0.0895\n",
            "Epoch 7/24\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.0713\n",
            "Epoch 8/24\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0566\n",
            "Epoch 9/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0502 - val_loss: 0.0459\n",
            "Epoch 10/24\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0391 - val_loss: 0.0395\n",
            "Epoch 11/24\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0346\n",
            "Epoch 12/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0306\n",
            "Epoch 13/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0280\n",
            "Epoch 14/24\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0259\n",
            "Epoch 15/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0242\n",
            "Epoch 16/24\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0230\n",
            "Epoch 17/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0221\n",
            "Epoch 18/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0214\n",
            "Epoch 19/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0206\n",
            "Epoch 20/24\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0200\n",
            "Epoch 21/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0197\n",
            "Epoch 22/24\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0192\n",
            "Epoch 23/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0187\n",
            "Epoch 24/24\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0183\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpz1akeihd/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.06935200655981462\n",
            "  MAE: 0.05265262900507077\n",
            "  R2: -746.1379905044769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:56:13,409]\u001b[0m Trial 8 finished with value: 0.06935200655981462 and parameters: {'hidden_units': 11, 'lr': 0.0004198674582428264, 'epochs': 24}. Best is trial 6 with value: 0.01909312589403764.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 9)                 99        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 10        \n",
            "=================================================================\n",
            "Total params: 310\n",
            "Trainable params: 289\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/17\n",
            " 3/19 [===>..........................] - ETA: 0s - loss: 1.5161WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0134s). Check your callbacks.\n",
            "19/19 [==============================] - 1s 18ms/step - loss: 2.1980 - val_loss: 1.3545\n",
            "Epoch 2/17\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 1.7073 - val_loss: 1.0799\n",
            "Epoch 3/17\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3405 - val_loss: 0.8760\n",
            "Epoch 4/17\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0845 - val_loss: 0.7253\n",
            "Epoch 5/17\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.8827 - val_loss: 0.6082\n",
            "Epoch 6/17\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7332 - val_loss: 0.5141\n",
            "Epoch 7/17\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.6144 - val_loss: 0.4417\n",
            "Epoch 8/17\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5186 - val_loss: 0.3795\n",
            "Epoch 9/17\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4460 - val_loss: 0.3280\n",
            "Epoch 10/17\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3801 - val_loss: 0.2855\n",
            "Epoch 11/17\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.2516\n",
            "Epoch 12/17\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2838 - val_loss: 0.2216\n",
            "Epoch 13/17\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.2505 - val_loss: 0.1963\n",
            "Epoch 14/17\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2184 - val_loss: 0.1734\n",
            "Epoch 15/17\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1909 - val_loss: 0.1556\n",
            "Epoch 16/17\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1693 - val_loss: 0.1397\n",
            "Epoch 17/17\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1507 - val_loss: 0.1256\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpkwajgr_r/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.34464425675847316\n",
            "  MAE: 0.23940602102903646\n",
            "  R2: -18450.209897724333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:56:18,664]\u001b[0m Trial 9 finished with value: 0.34464425675847316 and parameters: {'hidden_units': 9, 'lr': 0.00032911589336186647, 'epochs': 17}. Best is trial 6 with value: 0.01909312589403764.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM_kbNyrLssM"
      },
      "source": [
        "###Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7NqTLYULt3i"
      },
      "source": [
        "def random_forest(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 5),\n",
        "    }\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "    \n",
        "    with mlflow.start_run(run_name=\"Random Forest\"):\n",
        "        rf = RandomForestRegressor(\n",
        "            max_depth=params[\"max_depth\"],\n",
        "            n_estimators=params[\"n_estimators\"],\n",
        "            min_samples_split=params[\"min_samples_split\"],\n",
        "            random_state=0\n",
        "        )\n",
        "        rf.fit(train, train_labels)\n",
        "        \n",
        "        predictions = rf.predict(val)\n",
        "        \n",
        "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
        "        \n",
        "        print(\"Random Forest model\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "        print(\"  R2: %s\" % r2)\n",
        "        \n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"r2\", r2)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        mlflow.log_params(trial.params)\n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdHSTFZeLxrs",
        "outputId": "ce865fc5-6add-475f-8867-0d140ed98063"
      },
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(random_forest, n_trials=10)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:57:52,265]\u001b[0m A new study created in memory with name: no-name-7e88c718-f0c5-4b95-aaa6-a2cb437be7f2\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.03076379686953024\n",
            "  MAE: 0.019045805482472918\n",
            "  R2: -146.01533170170387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:57:53,410]\u001b[0m Trial 0 finished with value: 0.03076379686953024 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 4}. Best is trial 0 with value: 0.03076379686953024.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.031478965602240096\n",
            "  MAE: 0.02007207003657248\n",
            "  R2: -152.9301398659441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:57:54,740]\u001b[0m Trial 1 finished with value: 0.031478965602240096 and parameters: {'n_estimators': 99, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 0 with value: 0.03076379686953024.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.029616873714326346\n",
            "  MAE: 0.01890766043391612\n",
            "  R2: -135.25774114335613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:57:55,796]\u001b[0m Trial 2 finished with value: 0.029616873714326346 and parameters: {'n_estimators': 73, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 2 with value: 0.029616873714326346.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.030760900747649724\n",
            "  MAE: 0.019202389971709363\n",
            "  R2: -145.98765278551573\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:57:56,904]\u001b[0m Trial 3 finished with value: 0.030760900747649724 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 4}. Best is trial 2 with value: 0.029616873714326346.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.03221053816097292\n",
            "  MAE: 0.019588966176623646\n",
            "  R2: -160.16796405739692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:57:58,154]\u001b[0m Trial 4 finished with value: 0.03221053816097292 and parameters: {'n_estimators': 103, 'max_depth': 7, 'min_samples_split': 4}. Best is trial 2 with value: 0.029616873714326346.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.02855276636257497\n",
            "  MAE: 0.018795314645370785\n",
            "  R2: -125.64240263390958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:57:59,286]\u001b[0m Trial 5 finished with value: 0.02855276636257497 and parameters: {'n_estimators': 133, 'max_depth': 4, 'min_samples_split': 4}. Best is trial 5 with value: 0.02855276636257497.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.0311229162396177\n",
            "  MAE: 0.018852379618323086\n",
            "  R2: -149.46771499157427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:58:00,673]\u001b[0m Trial 6 finished with value: 0.0311229162396177 and parameters: {'n_estimators': 104, 'max_depth': 6, 'min_samples_split': 4}. Best is trial 5 with value: 0.02855276636257497.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.03232207083849229\n",
            "  MAE: 0.020193064384042038\n",
            "  R2: -161.2860214817109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:58:02,087]\u001b[0m Trial 7 finished with value: 0.03232207083849229 and parameters: {'n_estimators': 127, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 5 with value: 0.02855276636257497.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.032979007299821846\n",
            "  MAE: 0.02042099620748074\n",
            "  R2: -167.9498908709441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:58:03,404]\u001b[0m Trial 8 finished with value: 0.032979007299821846 and parameters: {'n_estimators': 92, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 5 with value: 0.02855276636257497.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.03235252028314271\n",
            "  MAE: 0.020362194924787847\n",
            "  R2: -161.59193299746187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 22:58:04,921]\u001b[0m Trial 9 finished with value: 0.03235252028314271 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2}. Best is trial 5 with value: 0.02855276636257497.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q5kxu8PMNpw"
      },
      "source": [
        "###Gradient boost com lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegzHTIqMV-n"
      },
      "source": [
        "def gradient_boosting(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 25, 35),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10)\n",
        "    }\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "    \n",
        "    with mlflow.start_run(run_name=\"Gradient Boosting\"):\n",
        "#         model = LGBMRegressor(\n",
        "#             max_depth=params[\"max_depth\"],\n",
        "#             n_estimators=params[\"n_estimators\"],\n",
        "#             num_leaves=params[\"num_leaves\"],\n",
        "#         )\n",
        "        model = XGBRegressor(\n",
        "            max_depth=params[\"max_depth\"],\n",
        "            n_estimators=params[\"n_estimators\"],\n",
        "        )\n",
        "        model.fit(train, train_labels)\n",
        "        \n",
        "        predictions = model.predict(test)\n",
        "        print('Prediction: %.3f' % predictions[0])\n",
        "        \n",
        "        (rmse, mae, r2) = eval_metrics(val_labels, predictions)\n",
        "\n",
        "        print(\"LGBM model\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "        print(\"  R2: %s\" % r2)\n",
        "\n",
        "        # Log mlflow attributes for mlflow UI\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"r2\", r2)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        mlflow.log_params(trial.params)\n",
        "        mlflow.set_tags(\n",
        "            {\n",
        "                \"estimator_class\":\"LightGBM\",\n",
        "                \"estimator_name\":\"Gradient Boosting\"\n",
        "            }\n",
        "        )\n",
        "        mlflow.sklearn.log_model(model, \"model\")\n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MA5E8HHMbRd",
        "outputId": "a0764852-0552-4e08-ff46-57dfc844fead"
      },
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(gradient_boosting, n_trials=10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:25,969]\u001b[0m A new study created in memory with name: no-name-987ccfdd-2347-4d05-9a79-b48875b7dfaf\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.004\n",
            "LGBM model\n",
            "  RMSE: 0.04059447506877251\n",
            "  MAE: 0.023190308749675755\n",
            "  R2: -254.98623784220482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:26,744]\u001b[0m Trial 0 finished with value: 0.04059447506877251 and parameters: {'n_estimators': 143, 'num_leaves': 26, 'max_depth': 5}. Best is trial 0 with value: 0.04059447506877251.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.006\n",
            "LGBM model\n",
            "  RMSE: 0.039719294511375125\n",
            "  MAE: 0.022940721303224568\n",
            "  R2: -244.06755052137538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:27,586]\u001b[0m Trial 1 finished with value: 0.039719294511375125 and parameters: {'n_estimators': 124, 'num_leaves': 26, 'max_depth': 5}. Best is trial 1 with value: 0.039719294511375125.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.009\n",
            "LGBM model\n",
            "  RMSE: 0.03465405939213558\n",
            "  MAE: 0.0209403303861618\n",
            "  R2: -185.5481681326075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:28,335]\u001b[0m Trial 2 finished with value: 0.03465405939213558 and parameters: {'n_estimators': 68, 'num_leaves': 27, 'max_depth': 4}. Best is trial 2 with value: 0.03465405939213558.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.016\n",
            "LGBM model\n",
            "  RMSE: 0.03985484585490384\n",
            "  MAE: 0.021008634626865384\n",
            "  R2: -245.74310495039163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:29,100]\u001b[0m Trial 3 finished with value: 0.03985484585490384 and parameters: {'n_estimators': 70, 'num_leaves': 35, 'max_depth': 6}. Best is trial 2 with value: 0.03465405939213558.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.005\n",
            "LGBM model\n",
            "  RMSE: 0.04034265173067494\n",
            "  MAE: 0.023087901413440706\n",
            "  R2: -251.8201240640823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:29,933]\u001b[0m Trial 4 finished with value: 0.04034265173067494 and parameters: {'n_estimators': 136, 'num_leaves': 35, 'max_depth': 5}. Best is trial 2 with value: 0.03465405939213558.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: -0.001\n",
            "LGBM model\n",
            "  RMSE: 0.03402010992262072\n",
            "  MAE: 0.019358340710401534\n",
            "  R2: -178.78530161509855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:30,715]\u001b[0m Trial 5 finished with value: 0.03402010992262072 and parameters: {'n_estimators': 111, 'num_leaves': 25, 'max_depth': 10}. Best is trial 5 with value: 0.03402010992262072.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.007\n",
            "LGBM model\n",
            "  RMSE: 0.03974175840906631\n",
            "  MAE: 0.020689090430736544\n",
            "  R2: -244.34483284576203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:31,601]\u001b[0m Trial 6 finished with value: 0.03974175840906631 and parameters: {'n_estimators': 121, 'num_leaves': 33, 'max_depth': 7}. Best is trial 5 with value: 0.03402010992262072.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.003\n",
            "LGBM model\n",
            "  RMSE: 0.03580880262949954\n",
            "  MAE: 0.019638554406166076\n",
            "  R2: -198.18762652558502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:32,360]\u001b[0m Trial 7 finished with value: 0.03580880262949954 and parameters: {'n_estimators': 102, 'num_leaves': 35, 'max_depth': 9}. Best is trial 5 with value: 0.03402010992262072.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.006\n",
            "LGBM model\n",
            "  RMSE: 0.03995935384494424\n",
            "  MAE: 0.023054923653602604\n",
            "  R2: -247.0388286921104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:33,089]\u001b[0m Trial 8 finished with value: 0.03995935384494424 and parameters: {'n_estimators': 131, 'num_leaves': 31, 'max_depth': 5}. Best is trial 5 with value: 0.03402010992262072.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[23:00:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.003\n",
            "LGBM model\n",
            "  RMSE: 0.040808810350956896\n",
            "  MAE: 0.023329358160495754\n",
            "  R2: -257.69654404044536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 23:00:33,960]\u001b[0m Trial 9 finished with value: 0.040808810350956896 and parameters: {'n_estimators': 143, 'num_leaves': 31, 'max_depth': 4}. Best is trial 5 with value: 0.03402010992262072.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}