{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto 2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ladsong/if697-2020.2-data-science/blob/projeto2/Projeto_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP7bSbbR0eNH"
      },
      "source": [
        "##Preparando o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZrgWPKwwqDA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import gc\n",
        "import warnings\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6U08MfwzZqI",
        "outputId": "e883e76c-8352-413a-ada5-990ba8162472"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmM_Ob5nzhzR",
        "outputId": "232b781b-3d56-4e53-faf3-d70e45769a6d"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "# /content/gdrive/My Drive/Kaggle é o caminho onde o arquivo kaggle.json está presente do Google Drive\n",
        "#Mudar o diretorio\n",
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPPNFhH6zqyn"
      },
      "source": [
        "##Carregando o dataset e processando os dados\n",
        "No projeto 1, foi adicionado o dump dos dados para que possamos utiliza-los aqui. O objetivo desse projeto é predizer a popularidade de uma música através de suas caracteristicas informadas no subset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950oJnwAzuQa"
      },
      "source": [
        "df = pd.read_csv('project1_output.csv')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDXvjdgL1E3C"
      },
      "source": [
        "Observamos que o dataset é grande e assim decidimos utilizar um subset  com o objetivo de diminuir o tempo de experimentação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAzyCDNI1B2p",
        "outputId": "27d1e6a1-a317-444b-8173-9273bc3f1fe4"
      },
      "source": [
        "df = df[:5000]\n",
        "df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
        "df.dtypes"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "year                   int64\n",
              "acousticness         float64\n",
              "artists_data          object\n",
              "danceability         float64\n",
              "duration_ms            int64\n",
              "energy               float64\n",
              "explicit               int64\n",
              "id                    object\n",
              "instrumentalness     float64\n",
              "loudness             float64\n",
              "name                  object\n",
              "popularity           float64\n",
              "release_date          object\n",
              "speechiness          float64\n",
              "tempo                float64\n",
              "first_artist          object\n",
              "artists_by_artist     object\n",
              "first_genre           object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PG6pe_RQJk3"
      },
      "source": [
        "Tirando colunas desnecessárias, como `artist_data, id, name, release_date, first_artist, artists_by_artist` e `first_genre,` pois só queremos trabalhar com valores numéricos\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmVGx9hJQW0B"
      },
      "source": [
        "df = df.select_dtypes(exclude=['object'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggg_wtCGQc-w",
        "outputId": "ea07d8b8-fc3f-4144-d397-22701ca864ff"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['year', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
              "       'explicit', 'instrumentalness', 'loudness', 'popularity', 'speechiness',\n",
              "       'tempo'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U48qY0V8RXrQ"
      },
      "source": [
        "\n",
        "\n",
        "###Escolher coluna para predição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30gxMAGvRe4u"
      },
      "source": [
        "target_col = df['popularity']"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-zjSp-7SPB-",
        "outputId": "49c7d7e8-bfe3-486a-d640-3cc58124d6bf"
      },
      "source": [
        "target_col"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.04\n",
              "1       0.02\n",
              "2       0.04\n",
              "3       0.00\n",
              "4       0.01\n",
              "        ... \n",
              "4995    0.00\n",
              "4996    0.00\n",
              "4997    0.00\n",
              "4998    0.00\n",
              "4999    0.00\n",
              "Name: popularity, Length: 5000, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ6TKxGGSdUq"
      },
      "source": [
        "df = df.drop(columns=['popularity'])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp4z9GRaS2li"
      },
      "source": [
        "##Separando os dados em teste e predição\n",
        "Para realizacão do treinamento, teste e vaidacão, iremos separa o subset em: \n",
        "\n",
        "*   3/5 dos dados para treinamento\n",
        "*   1/5 dos dados para teste \n",
        "*   1/5 dos dados para validacão\n",
        "\n",
        "Seguindo assim, uma base 60/20/20\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llnzPoPOS8-l"
      },
      "source": [
        "def get_x_data():\n",
        "    # input \n",
        "    train, val, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
        "    \n",
        "    return train, val, test"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWlYxs_nvjhR"
      },
      "source": [
        "def get_y_data():\n",
        "    # output\n",
        "    train_labels, val_labels, test_labels = (\n",
        "        np.split(\n",
        "            target_col, \n",
        "            [int(.6*len(target_col)), int(.8*len(target_col))])\n",
        "    )\n",
        "    \n",
        "    return train_labels, val_labels, test_labels"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lu5e9X9vsBw"
      },
      "source": [
        "##Escolher os 4 algoritmos para predição"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYbNEFCzEsBU"
      },
      "source": [
        "Os algoritmos de predicão que iremos usar são:\n",
        "\n",
        "*   Regressão Linear\n",
        "*   Multilayer perceptron\n",
        "*   Random forests\n",
        "*   Gradient boost com lightgbm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh6drbfgHj1I"
      },
      "source": [
        "!pip install mlflow --quiet"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0cVUQd7JL_H",
        "outputId": "9c8239d0-75f3-4cab-f73e-5deb5bb528e4"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (5.0.1)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.22)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.1)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.4)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.6.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n-LB6i-HaTv"
      },
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import optuna\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import lightgbm\n",
        "from lightgbm import LGBMRegressor"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFdO3ZS2Jmyg"
      },
      "source": [
        "#Função de avaliação das metricas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Qm1Z9QJqJI"
      },
      "source": [
        "def eval_metrics(actual, pred):\n",
        "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "    mae = mean_absolute_error(actual, pred)\n",
        "    return rmse, mae"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnE6KnfvJ1WN",
        "outputId": "099a76fb-c478-48f8-8536-a7581fc8f258"
      },
      "source": [
        "mlflow.sklearn.autolog()\n",
        "mlflow.tensorflow.autolog()\n",
        "mlflow.lightgbm.autolog()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/08/17 01:17:23 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of lightgbm. If you encounter errors during autologging, try upgrading / downgrading lightgbm to a supported version, or try upgrading MLflow.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcv8mZ28J8MX"
      },
      "source": [
        "###Regressão Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-NWvytLJ7uY"
      },
      "source": [
        "def linear_regression(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "\n",
        "    with mlflow.start_run(run_name=\"Linear Regression\"):\n",
        "        reg = LinearRegression()\n",
        "        reg.fit(train, train_labels)\n",
        "\n",
        "        predictions = reg.predict(val)\n",
        "\n",
        "        (rmse, mae) = eval_metrics(val_labels, predictions)\n",
        "\n",
        "        print(\"Modelo de regressão linear\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        \n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyu7BWpJKFkd",
        "outputId": "83d9e5d4-8409-41d5-f6e9-b47448819331"
      },
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(linear_regression, n_trials=1)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:17:36,432]\u001b[0m A new study created in memory with name: no-name-50d9be8c-8a38-4b20-b1eb-ae94e3bf35eb\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Modelo de regressão linear\n",
            "  RMSE: 0.13007774724559681\n",
            "  MAE: 0.08351024898801312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:17:36,954]\u001b[0m Trial 0 finished with value: 0.13007774724559681 and parameters: {}. Best is trial 0 with value: 0.13007774724559681.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMU8ss6ULFv_"
      },
      "source": [
        "###Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a1ihwwcLHoe"
      },
      "source": [
        "def mlp(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    params = {\n",
        "        \"hidden_units\": trial.suggest_int(\"hidden_units\", 3, 15),\n",
        "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n",
        "        \"epochs\": trial.suggest_int(\"epochs\", 10, 50)\n",
        "    }\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "    \n",
        "    with mlflow.start_run(run_name=\"MLP\"):\n",
        "        normalizer = preprocessing.Normalization(axis=-1)\n",
        "        normalizer.adapt(np.array(train))\n",
        "        \n",
        "        mlp_model = tf.keras.Sequential([\n",
        "            normalizer,\n",
        "            layers.Dense(units=params[\"hidden_units\"]),\n",
        "            layers.Dense(units=params[\"hidden_units\"]),\n",
        "            layers.Dense(units=params[\"hidden_units\"]),\n",
        "            layers.Dense(units=1),\n",
        "        ])\n",
        "\n",
        "        mlp_model.summary()\n",
        "        \n",
        "        mlp_model.compile(\n",
        "            optimizer=tf.optimizers.Adam(learning_rate=params[\"lr\"]),\n",
        "            loss='mean_squared_error'\n",
        "        )\n",
        "\n",
        "        history = mlp_model.fit(\n",
        "            train, train_labels,\n",
        "            validation_data=(test, test_labels),\n",
        "            epochs=params[\"epochs\"]\n",
        "        )\n",
        "        \n",
        "        predictions = mlp_model.predict(val)\n",
        "\n",
        "        (rmse, mae) = eval_metrics(val_labels, predictions)\n",
        "\n",
        "        print(\"MLP model\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        mlflow.log_params(trial.params)\n",
        "        mlflow.set_tags(\n",
        "            {\n",
        "                \"estimator_name\":\"MultiLayerPerceptron\",\n",
        "                \"estimator_class\":\"Keras\"\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMWfjUoYLPpm",
        "outputId": "622c98f3-ea0b-4fe0-a970-ccccbcb53f0b"
      },
      "source": [
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(mlp, n_trials=10)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:17:45,126]\u001b[0m A new study created in memory with name: no-name-cbdeedb0-58d5-4d93-be34-d9399d758b4a\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization_1 (Normalizati (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 14)                154       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 15        \n",
            "=================================================================\n",
            "Total params: 610\n",
            "Trainable params: 589\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/17\n",
            " 3/94 [..............................] - ETA: 3s - loss: 0.3379 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0111s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 0.4282 - val_loss: 0.5327\n",
            "Epoch 2/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3231 - val_loss: 0.4316\n",
            "Epoch 3/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2541 - val_loss: 0.3561\n",
            "Epoch 4/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2066 - val_loss: 0.3021\n",
            "Epoch 5/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1744 - val_loss: 0.2626\n",
            "Epoch 6/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1509 - val_loss: 0.2326\n",
            "Epoch 7/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.2088\n",
            "Epoch 8/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 0.1893\n",
            "Epoch 9/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1112 - val_loss: 0.1724\n",
            "Epoch 10/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.1579\n",
            "Epoch 11/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.1462\n",
            "Epoch 12/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.1338\n",
            "Epoch 13/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.1210\n",
            "Epoch 14/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.1135\n",
            "Epoch 15/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.1007\n",
            "Epoch 16/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0921\n",
            "Epoch 17/17\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0836\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpwt79ysld/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.3674490223143016\n",
            "  MAE: 0.16186277681370267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:17:57,155]\u001b[0m Trial 0 finished with value: 0.3674490223143016 and parameters: {'hidden_units': 14, 'lr': 3.566083414277468e-05, 'epochs': 17}. Best is trial 0 with value: 0.3674490223143016.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 33        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 82\n",
            "Trainable params: 61\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/22\n",
            " 3/94 [..............................] - ETA: 3s - loss: 7.6354 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0115s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 6.9677 - val_loss: 6.7710\n",
            "Epoch 2/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 6.6274 - val_loss: 6.4461\n",
            "Epoch 3/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 6.3154 - val_loss: 6.1535\n",
            "Epoch 4/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 6.0217 - val_loss: 5.8682\n",
            "Epoch 5/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 5.7430 - val_loss: 5.6059\n",
            "Epoch 6/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 5.4834 - val_loss: 5.3548\n",
            "Epoch 7/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 5.2369 - val_loss: 5.1239\n",
            "Epoch 8/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 5.0064 - val_loss: 4.8974\n",
            "Epoch 9/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 4.7861 - val_loss: 4.6920\n",
            "Epoch 10/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 4.5789 - val_loss: 4.4930\n",
            "Epoch 11/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 4.3844 - val_loss: 4.2985\n",
            "Epoch 12/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 4.1976 - val_loss: 4.1207\n",
            "Epoch 13/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 4.0206 - val_loss: 3.9517\n",
            "Epoch 14/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3.8528 - val_loss: 3.7874\n",
            "Epoch 15/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3.6911 - val_loss: 3.6309\n",
            "Epoch 16/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3.5375 - val_loss: 3.4866\n",
            "Epoch 17/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3.3920 - val_loss: 3.3396\n",
            "Epoch 18/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3.2530 - val_loss: 3.2037\n",
            "Epoch 19/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3.1198 - val_loss: 3.0787\n",
            "Epoch 20/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.9939 - val_loss: 2.9533\n",
            "Epoch 21/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.8726 - val_loss: 2.8358\n",
            "Epoch 22/22\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.7571 - val_loss: 2.7234\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp6ems_1kr/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 1.597210751913307\n",
            "  MAE: 0.9991966551731339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:18:04,588]\u001b[0m Trial 1 finished with value: 1.597210751913307 and parameters: {'hidden_units': 3, 'lr': 4.2617695824325495e-05, 'epochs': 22}. Best is trial 0 with value: 0.3674490223143016.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7)                 77        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 8         \n",
            "=================================================================\n",
            "Total params: 218\n",
            "Trainable params: 197\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/44\n",
            " 3/94 [..............................] - ETA: 3s - loss: 0.1624 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0111s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 0.2496 - val_loss: 0.2511\n",
            "Epoch 2/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2048 - val_loss: 0.2156\n",
            "Epoch 3/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1726 - val_loss: 0.1877\n",
            "Epoch 4/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.1647\n",
            "Epoch 5/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1278 - val_loss: 0.1471\n",
            "Epoch 6/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1119 - val_loss: 0.1289\n",
            "Epoch 7/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.1142\n",
            "Epoch 8/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.1014\n",
            "Epoch 9/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0905\n",
            "Epoch 10/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0802\n",
            "Epoch 11/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0714\n",
            "Epoch 12/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0636\n",
            "Epoch 13/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0570\n",
            "Epoch 14/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0503\n",
            "Epoch 15/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0446\n",
            "Epoch 16/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0397\n",
            "Epoch 17/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0362\n",
            "Epoch 18/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0314\n",
            "Epoch 19/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0282\n",
            "Epoch 20/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0250\n",
            "Epoch 21/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0223\n",
            "Epoch 22/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0203\n",
            "Epoch 23/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0178\n",
            "Epoch 24/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0161\n",
            "Epoch 25/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0149\n",
            "Epoch 26/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0135\n",
            "Epoch 27/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0123\n",
            "Epoch 28/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0109\n",
            "Epoch 29/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0099\n",
            "Epoch 30/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0093\n",
            "Epoch 31/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0086\n",
            "Epoch 32/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0078\n",
            "Epoch 33/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0073\n",
            "Epoch 34/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0068\n",
            "Epoch 35/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0063\n",
            "Epoch 36/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0060\n",
            "Epoch 37/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0055\n",
            "Epoch 38/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0053\n",
            "Epoch 39/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0049\n",
            "Epoch 40/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0048\n",
            "Epoch 41/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0046\n",
            "Epoch 42/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0043\n",
            "Epoch 43/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0040\n",
            "Epoch 44/44\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0040\n",
            "INFO:tensorflow:Assets written to: /tmp/tmprzvc5f6b/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.13499030385042662\n",
            "  MAE: 0.08624953857347369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:18:16,605]\u001b[0m Trial 2 finished with value: 0.13499030385042662 and parameters: {'hidden_units': 7, 'lr': 6.873920055800635e-05, 'epochs': 44}. Best is trial 2 with value: 0.13499030385042662.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 13)                143       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 542\n",
            "Trainable params: 521\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/37\n",
            " 3/94 [..............................] - ETA: 3s - loss: 2.5673 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0116s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 1.9708 - val_loss: 1.2341\n",
            "Epoch 2/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.8932 - val_loss: 0.6422\n",
            "Epoch 3/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 0.3591\n",
            "Epoch 4/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2365 - val_loss: 0.2002\n",
            "Epoch 5/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1307 - val_loss: 0.1074\n",
            "Epoch 6/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0634\n",
            "Epoch 7/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0387\n",
            "Epoch 8/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0256\n",
            "Epoch 9/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0188\n",
            "Epoch 10/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0143\n",
            "Epoch 11/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0118\n",
            "Epoch 12/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0097\n",
            "Epoch 13/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0078\n",
            "Epoch 14/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0068\n",
            "Epoch 15/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0064\n",
            "Epoch 16/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0052\n",
            "Epoch 17/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0051\n",
            "Epoch 18/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0044\n",
            "Epoch 19/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0041\n",
            "Epoch 20/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0042\n",
            "Epoch 21/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0036\n",
            "Epoch 22/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0036\n",
            "Epoch 23/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0039\n",
            "Epoch 24/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0032\n",
            "Epoch 25/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0031\n",
            "Epoch 26/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0033\n",
            "Epoch 27/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0034\n",
            "Epoch 28/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0029\n",
            "Epoch 29/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0032\n",
            "Epoch 30/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0034\n",
            "Epoch 31/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0030\n",
            "Epoch 32/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0028\n",
            "Epoch 33/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0029\n",
            "Epoch 34/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0033\n",
            "Epoch 35/37\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0031\n",
            "Epoch 36/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0034\n",
            "Epoch 37/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0037\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpb54suhio/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.12948633635721293\n",
            "  MAE: 0.08544548932597042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:18:28,665]\u001b[0m Trial 3 finished with value: 0.12948633635721293 and parameters: {'hidden_units': 13, 'lr': 0.0001467568330615016, 'epochs': 37}. Best is trial 3 with value: 0.12948633635721293.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 13)                143       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 542\n",
            "Trainable params: 521\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/43\n",
            " 3/94 [..............................] - ETA: 4s - loss: 1.0570 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0159s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.9707 - val_loss: 0.8765\n",
            "Epoch 2/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5801 - val_loss: 0.5813\n",
            "Epoch 3/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3818\n",
            "Epoch 4/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2453 - val_loss: 0.2559\n",
            "Epoch 5/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1688 - val_loss: 0.1763\n",
            "Epoch 6/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1200 - val_loss: 0.1216\n",
            "Epoch 7/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.0851\n",
            "Epoch 8/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0596\n",
            "Epoch 9/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0417\n",
            "Epoch 10/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0289\n",
            "Epoch 11/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0203\n",
            "Epoch 12/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0146\n",
            "Epoch 13/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0106\n",
            "Epoch 14/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0082\n",
            "Epoch 15/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0065\n",
            "Epoch 16/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0055\n",
            "Epoch 17/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0048\n",
            "Epoch 18/43\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0044\n",
            "Epoch 19/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0041\n",
            "Epoch 20/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0039\n",
            "Epoch 21/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0037\n",
            "Epoch 22/43\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0034\n",
            "Epoch 23/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0033\n",
            "Epoch 24/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0032\n",
            "Epoch 25/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0033\n",
            "Epoch 26/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0031\n",
            "Epoch 27/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0030\n",
            "Epoch 28/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0029\n",
            "Epoch 29/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0030\n",
            "Epoch 30/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0030\n",
            "Epoch 31/43\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0029\n",
            "Epoch 32/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0030\n",
            "Epoch 33/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0028\n",
            "Epoch 34/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0028\n",
            "Epoch 35/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0030\n",
            "Epoch 36/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0030\n",
            "Epoch 37/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0027\n",
            "Epoch 38/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0032\n",
            "Epoch 39/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0032\n",
            "Epoch 40/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0032\n",
            "Epoch 41/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0026\n",
            "Epoch 42/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0031\n",
            "Epoch 43/43\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0031\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpkye_2r67/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.12994271856002898\n",
            "  MAE: 0.08407823680736123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:18:41,295]\u001b[0m Trial 4 finished with value: 0.12994271856002898 and parameters: {'hidden_units': 13, 'lr': 9.418718530131483e-05, 'epochs': 43}. Best is trial 3 with value: 0.12948633635721293.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 14)                154       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 15        \n",
            "=================================================================\n",
            "Total params: 610\n",
            "Trainable params: 589\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/41\n",
            " 3/94 [..............................] - ETA: 3s - loss: 0.8599 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0134s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 0.2399 - val_loss: 0.0388\n",
            "Epoch 2/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0054\n",
            "Epoch 3/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0030\n",
            "Epoch 4/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0032\n",
            "Epoch 5/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0029\n",
            "Epoch 6/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0051\n",
            "Epoch 7/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0037\n",
            "Epoch 8/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0034\n",
            "Epoch 9/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0014\n",
            "Epoch 10/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0032\n",
            "Epoch 11/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0047\n",
            "Epoch 12/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0036\n",
            "Epoch 13/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0027\n",
            "Epoch 14/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0051\n",
            "Epoch 15/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0045\n",
            "Epoch 16/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0117\n",
            "Epoch 17/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0142\n",
            "Epoch 18/41\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0120\n",
            "Epoch 19/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0262\n",
            "Epoch 20/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0086\n",
            "Epoch 21/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0033\n",
            "Epoch 22/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0037\n",
            "Epoch 23/41\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0027\n",
            "Epoch 24/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0042\n",
            "Epoch 25/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0024\n",
            "Epoch 26/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0037\n",
            "Epoch 27/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0049\n",
            "Epoch 28/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0051\n",
            "Epoch 29/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0118\n",
            "Epoch 30/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0108\n",
            "Epoch 31/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0150\n",
            "Epoch 32/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0067\n",
            "Epoch 33/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0055\n",
            "Epoch 34/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0059\n",
            "Epoch 35/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0081\n",
            "Epoch 36/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0091\n",
            "Epoch 37/41\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0378\n",
            "Epoch 38/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0035\n",
            "Epoch 39/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0034\n",
            "Epoch 40/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0036\n",
            "Epoch 41/41\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0028\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpvr780ijd/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.13176706403213764\n",
            "  MAE: 0.08304767136014998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:18:53,538]\u001b[0m Trial 5 finished with value: 0.13176706403213764 and parameters: {'hidden_units': 14, 'lr': 0.0007220704618852015, 'epochs': 41}. Best is trial 3 with value: 0.12948633635721293.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 9)                 99        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 10        \n",
            "=================================================================\n",
            "Total params: 310\n",
            "Trainable params: 289\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            " 3/94 [..............................] - ETA: 3s - loss: 6.8323 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0122s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 6.5429 - val_loss: 6.7854\n",
            "Epoch 2/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 5.2060 - val_loss: 5.4629\n",
            "Epoch 3/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 4.1969 - val_loss: 4.4531\n",
            "Epoch 4/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3.4243 - val_loss: 3.6626\n",
            "Epoch 5/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.8168 - val_loss: 3.0374\n",
            "Epoch 6/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.3332 - val_loss: 2.5368\n",
            "Epoch 7/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 1.9469 - val_loss: 2.1257\n",
            "Epoch 8/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 1.6341 - val_loss: 1.7952\n",
            "Epoch 9/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 1.3791 - val_loss: 1.5179\n",
            "Epoch 10/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 1.1642 - val_loss: 1.2875\n",
            "Epoch 11/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.9863 - val_loss: 1.0961\n",
            "Epoch 12/30\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.8380 - val_loss: 0.9316\n",
            "Epoch 13/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.7134 - val_loss: 0.7934\n",
            "Epoch 14/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6768\n",
            "Epoch 15/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 0.5783\n",
            "Epoch 16/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.5002\n",
            "Epoch 17/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.4217\n",
            "Epoch 18/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.3262 - val_loss: 0.3615\n",
            "Epoch 19/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2801 - val_loss: 0.3093\n",
            "Epoch 20/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2418 - val_loss: 0.2655\n",
            "Epoch 21/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2093 - val_loss: 0.2276\n",
            "Epoch 22/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1810 - val_loss: 0.1976\n",
            "Epoch 23/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1714\n",
            "Epoch 24/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1376 - val_loss: 0.1475\n",
            "Epoch 25/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1253\n",
            "Epoch 26/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1060 - val_loss: 0.1087\n",
            "Epoch 27/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.0940\n",
            "Epoch 28/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0818\n",
            "Epoch 29/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0718\n",
            "Epoch 30/30\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0616\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp_vvoiw3b/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.3023314311213293\n",
            "  MAE: 0.17800933794346638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:19:03,484]\u001b[0m Trial 6 finished with value: 0.3023314311213293 and parameters: {'hidden_units': 9, 'lr': 6.957766341766563e-05, 'epochs': 30}. Best is trial 3 with value: 0.12948633635721293.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 362\n",
            "Trainable params: 341\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/37\n",
            " 3/94 [..............................] - ETA: 3s - loss: 0.8876 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0133s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 0.4890 - val_loss: 0.1654\n",
            "Epoch 2/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0394\n",
            "Epoch 3/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0102\n",
            "Epoch 4/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0046\n",
            "Epoch 5/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0039\n",
            "Epoch 6/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0035\n",
            "Epoch 7/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0029\n",
            "Epoch 8/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0027\n",
            "Epoch 9/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0036\n",
            "Epoch 10/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0021\n",
            "Epoch 11/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0029\n",
            "Epoch 12/37\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0030\n",
            "Epoch 13/37\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0026\n",
            "Epoch 14/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0033\n",
            "Epoch 15/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0046\n",
            "Epoch 16/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0033\n",
            "Epoch 17/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0026\n",
            "Epoch 18/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0036\n",
            "Epoch 19/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0020\n",
            "Epoch 20/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0034\n",
            "Epoch 21/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0023\n",
            "Epoch 22/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0029\n",
            "Epoch 23/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0031\n",
            "Epoch 24/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0032\n",
            "Epoch 25/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0037\n",
            "Epoch 26/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0034\n",
            "Epoch 27/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0028\n",
            "Epoch 28/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0023\n",
            "Epoch 29/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0026\n",
            "Epoch 30/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0038\n",
            "Epoch 31/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0050\n",
            "Epoch 32/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0028\n",
            "Epoch 33/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0029\n",
            "Epoch 34/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0030\n",
            "Epoch 35/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0028\n",
            "Epoch 36/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0042\n",
            "Epoch 37/37\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0032\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpq0mbhj14/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.13129157540998543\n",
            "  MAE: 0.08461728907750919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:19:15,642]\u001b[0m Trial 7 finished with value: 0.13129157540998543 and parameters: {'hidden_units': 10, 'lr': 0.0003237035794040871, 'epochs': 37}. Best is trial 3 with value: 0.12948633635721293.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 66        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 178\n",
            "Trainable params: 157\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/49\n",
            " 3/94 [..............................] - ETA: 3s - loss: 0.4036 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0119s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 0.3998 - val_loss: 0.2858\n",
            "Epoch 2/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.2113 - val_loss: 0.1623\n",
            "Epoch 3/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1329 - val_loss: 0.1137\n",
            "Epoch 4/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.0860\n",
            "Epoch 5/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0699\n",
            "Epoch 6/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0544\n",
            "Epoch 7/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0443\n",
            "Epoch 8/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0358\n",
            "Epoch 9/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0310\n",
            "Epoch 10/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.0238\n",
            "Epoch 11/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0199\n",
            "Epoch 12/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0160\n",
            "Epoch 13/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0139\n",
            "Epoch 14/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0114\n",
            "Epoch 15/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0099\n",
            "Epoch 16/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0083\n",
            "Epoch 17/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0072\n",
            "Epoch 18/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0068\n",
            "Epoch 19/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0055\n",
            "Epoch 20/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0049\n",
            "Epoch 21/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0047\n",
            "Epoch 22/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0045\n",
            "Epoch 23/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0043\n",
            "Epoch 24/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0040\n",
            "Epoch 25/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0042\n",
            "Epoch 26/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0036\n",
            "Epoch 27/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0036\n",
            "Epoch 28/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0036\n",
            "Epoch 29/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0031\n",
            "Epoch 30/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0035\n",
            "Epoch 31/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0031\n",
            "Epoch 32/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0035\n",
            "Epoch 33/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0032\n",
            "Epoch 34/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0033\n",
            "Epoch 35/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0033\n",
            "Epoch 36/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0035\n",
            "Epoch 37/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0029\n",
            "Epoch 38/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0031\n",
            "Epoch 39/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0034\n",
            "Epoch 40/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0027\n",
            "Epoch 41/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0030\n",
            "Epoch 42/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0030\n",
            "Epoch 43/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0025\n",
            "Epoch 44/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0032\n",
            "Epoch 45/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0032\n",
            "Epoch 46/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0031\n",
            "Epoch 47/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0030\n",
            "Epoch 48/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0025\n",
            "Epoch 49/49\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0029\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp9n4txalh/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.13025249308712858\n",
            "  MAE: 0.08333108779922128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:19:38,045]\u001b[0m Trial 8 finished with value: 0.13025249308712858 and parameters: {'hidden_units': 6, 'lr': 0.00017408766108121688, 'epochs': 49}. Best is trial 3 with value: 0.12948633635721293.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 10)                21        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 11)                121       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 11)                132       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11)                132       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 418\n",
            "Trainable params: 397\n",
            "Non-trainable params: 21\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            " 3/94 [..............................] - ETA: 3s - loss: 0.5707 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0120s). Check your callbacks.\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 0.2438 - val_loss: 0.0856\n",
            "Epoch 2/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0230\n",
            "Epoch 3/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0083\n",
            "Epoch 4/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0045\n",
            "Epoch 5/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0031\n",
            "Epoch 6/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0027\n",
            "Epoch 7/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0032\n",
            "Epoch 8/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0028\n",
            "Epoch 9/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0019\n",
            "Epoch 10/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0026\n",
            "Epoch 11/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0017\n",
            "Epoch 12/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0036\n",
            "Epoch 13/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0027\n",
            "Epoch 14/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0035\n",
            "Epoch 15/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0029\n",
            "Epoch 16/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0034\n",
            "Epoch 17/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0027\n",
            "Epoch 18/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0023\n",
            "Epoch 19/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0028\n",
            "Epoch 20/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0054\n",
            "Epoch 21/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0048\n",
            "Epoch 22/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0033\n",
            "Epoch 23/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0034\n",
            "Epoch 24/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0038\n",
            "Epoch 25/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0028\n",
            "Epoch 26/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0043\n",
            "Epoch 27/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0037\n",
            "Epoch 28/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0039\n",
            "Epoch 29/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0035\n",
            "Epoch 30/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0046\n",
            "Epoch 31/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0037\n",
            "Epoch 32/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0048\n",
            "Epoch 33/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0016\n",
            "Epoch 34/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0040\n",
            "Epoch 35/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0057\n",
            "Epoch 36/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0046\n",
            "Epoch 37/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0045\n",
            "Epoch 38/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0051\n",
            "Epoch 39/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0045\n",
            "Epoch 40/40\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0043\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpfcv0u9n7/model/data/model/assets\n",
            "MLP model\n",
            "  RMSE: 0.12808454436221042\n",
            "  MAE: 0.08583547287218272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:19:49,931]\u001b[0m Trial 9 finished with value: 0.12808454436221042 and parameters: {'hidden_units': 11, 'lr': 0.0006410770284508693, 'epochs': 40}. Best is trial 9 with value: 0.12808454436221042.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM_kbNyrLssM"
      },
      "source": [
        "###Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7NqTLYULt3i"
      },
      "source": [
        "def random_forest(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 5),\n",
        "    }\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "    \n",
        "    with mlflow.start_run(run_name=\"Random Forest\"):\n",
        "        rf = RandomForestRegressor(\n",
        "            max_depth=params[\"max_depth\"],\n",
        "            n_estimators=params[\"n_estimators\"],\n",
        "            min_samples_split=params[\"min_samples_split\"],\n",
        "            random_state=0\n",
        "        )\n",
        "        rf.fit(train, train_labels)\n",
        "        \n",
        "        predictions = rf.predict(val)\n",
        "        \n",
        "        (rmse, mae) = eval_metrics(val_labels, predictions)\n",
        "        \n",
        "        print(\"Random Forest model\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "        \n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        mlflow.log_params(trial.params)\n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdHSTFZeLxrs",
        "outputId": "a85916e6-a31d-494c-e833-7d6cc6a7296b"
      },
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(random_forest, n_trials=10)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:18,889]\u001b[0m A new study created in memory with name: no-name-b479c938-bc2a-4aa3-984d-9537ac272c97\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.1314256592118017\n",
            "  MAE: 0.08515884839388493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:21,077]\u001b[0m Trial 0 finished with value: 0.1314256592118017 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 0 with value: 0.1314256592118017.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.1308495018336663\n",
            "  MAE: 0.08465131118158103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:23,357]\u001b[0m Trial 1 finished with value: 0.1308495018336663 and parameters: {'n_estimators': 122, 'max_depth': 7, 'min_samples_split': 2}. Best is trial 1 with value: 0.1308495018336663.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.13105243094581254\n",
            "  MAE: 0.08485392485558302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:24,943]\u001b[0m Trial 2 finished with value: 0.13105243094581254 and parameters: {'n_estimators': 62, 'max_depth': 8, 'min_samples_split': 3}. Best is trial 1 with value: 0.1308495018336663.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.13146618299193122\n",
            "  MAE: 0.08512712138234363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:27,167]\u001b[0m Trial 3 finished with value: 0.13146618299193122 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 1 with value: 0.1308495018336663.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.13104756281281413\n",
            "  MAE: 0.08477837352381126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:29,603]\u001b[0m Trial 4 finished with value: 0.13104756281281413 and parameters: {'n_estimators': 120, 'max_depth': 8, 'min_samples_split': 4}. Best is trial 1 with value: 0.1308495018336663.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.13117927744415908\n",
            "  MAE: 0.08495719411581604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:32,256]\u001b[0m Trial 5 finished with value: 0.13117927744415908 and parameters: {'n_estimators': 120, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 1 with value: 0.1308495018336663.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.13089874770936405\n",
            "  MAE: 0.08474632363199583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:33,967]\u001b[0m Trial 6 finished with value: 0.13089874770936405 and parameters: {'n_estimators': 77, 'max_depth': 7, 'min_samples_split': 4}. Best is trial 1 with value: 0.1308495018336663.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.13113398739037418\n",
            "  MAE: 0.08472899644465384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:36,730]\u001b[0m Trial 7 finished with value: 0.13113398739037418 and parameters: {'n_estimators': 148, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 1 with value: 0.1308495018336663.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.13088249166934718\n",
            "  MAE: 0.08483020271396965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:38,931]\u001b[0m Trial 8 finished with value: 0.13088249166934718 and parameters: {'n_estimators': 105, 'max_depth': 7, 'min_samples_split': 5}. Best is trial 1 with value: 0.1308495018336663.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest model\n",
            "  RMSE: 0.13104747490338675\n",
            "  MAE: 0.08456780324609338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:40,261]\u001b[0m Trial 9 finished with value: 0.13104747490338675 and parameters: {'n_estimators': 88, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 1 with value: 0.1308495018336663.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q5kxu8PMNpw"
      },
      "source": [
        "###Gradient boost com lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegzHTIqMV-n"
      },
      "source": [
        "def gradient_boosting(trial):\n",
        "    train, test, val = get_x_data()\n",
        "    train_labels, val_labels, test_labels = get_y_data()\n",
        "    \n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 150),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 25, 35),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10)\n",
        "    }\n",
        "    \n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    np.random.seed(40)\n",
        "    \n",
        "    with mlflow.start_run(run_name=\"Gradient Boosting\"):\n",
        "        model = XGBRegressor(\n",
        "            max_depth=params[\"max_depth\"],\n",
        "            n_estimators=params[\"n_estimators\"],\n",
        "        )\n",
        "        model.fit(train, train_labels)\n",
        "        \n",
        "        predictions = model.predict(test)\n",
        "        print('Prediction: %.3f' % predictions[0])\n",
        "        \n",
        "        (rmse, mae) = eval_metrics(val_labels, predictions)\n",
        "\n",
        "        print(\"LGBM model\")\n",
        "        print(\"  RMSE: %s\" % rmse)\n",
        "        print(\"  MAE: %s\" % mae)\n",
        "\n",
        "        # Log mlflow attributes for mlflow UI\n",
        "        mlflow.log_metric(\"rmse\", rmse)\n",
        "        mlflow.log_metric(\"mae\", mae)\n",
        "        mlflow.log_params(trial.params)\n",
        "        mlflow.set_tags(\n",
        "            {\n",
        "                \"estimator_class\":\"LightGBM\",\n",
        "                \"estimator_name\":\"Gradient Boosting\"\n",
        "            }\n",
        "        )\n",
        "        mlflow.sklearn.log_model(model, \"model\")\n",
        "        \n",
        "        gc.collect()\n",
        "        \n",
        "        return rmse"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MA5E8HHMbRd",
        "outputId": "f68895b5-04c5-460e-bb87-99e9b9ca4cdf"
      },
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(gradient_boosting, n_trials=10)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:50,679]\u001b[0m A new study created in memory with name: no-name-33bff1bf-22a2-4dae-b789-be0ba5bdf38b\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.047\n",
            "LGBM model\n",
            "  RMSE: 0.13193137386516426\n",
            "  MAE: 0.0849083552324772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:51,500]\u001b[0m Trial 0 finished with value: 0.13193137386516426 and parameters: {'n_estimators': 80, 'num_leaves': 35, 'max_depth': 4}. Best is trial 0 with value: 0.13193137386516426.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.053\n",
            "LGBM model\n",
            "  RMSE: 0.1309694932155369\n",
            "  MAE: 0.08409614305257795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:52,193]\u001b[0m Trial 1 finished with value: 0.1309694932155369 and parameters: {'n_estimators': 94, 'num_leaves': 25, 'max_depth': 2}. Best is trial 1 with value: 0.1309694932155369.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.027\n",
            "LGBM model\n",
            "  RMSE: 0.13748194357603463\n",
            "  MAE: 0.08948320661306382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:53,574]\u001b[0m Trial 2 finished with value: 0.13748194357603463 and parameters: {'n_estimators': 140, 'num_leaves': 30, 'max_depth': 7}. Best is trial 1 with value: 0.1309694932155369.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.049\n",
            "LGBM model\n",
            "  RMSE: 0.1311140683268585\n",
            "  MAE: 0.08431868470549583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:54,282]\u001b[0m Trial 3 finished with value: 0.1311140683268585 and parameters: {'n_estimators': 57, 'num_leaves': 29, 'max_depth': 4}. Best is trial 1 with value: 0.1309694932155369.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.026\n",
            "LGBM model\n",
            "  RMSE: 0.13571364493282384\n",
            "  MAE: 0.08876396795272828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:55,277]\u001b[0m Trial 4 finished with value: 0.13571364493282384 and parameters: {'n_estimators': 78, 'num_leaves': 31, 'max_depth': 8}. Best is trial 1 with value: 0.1309694932155369.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.041\n",
            "LGBM model\n",
            "  RMSE: 0.13310145330378742\n",
            "  MAE: 0.0854999857211113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:56,146]\u001b[0m Trial 5 finished with value: 0.13310145330378742 and parameters: {'n_estimators': 124, 'num_leaves': 31, 'max_depth': 4}. Best is trial 1 with value: 0.1309694932155369.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.020\n",
            "LGBM model\n",
            "  RMSE: 0.13553866299464548\n",
            "  MAE: 0.0875528560936451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:57,258]\u001b[0m Trial 6 finished with value: 0.13553866299464548 and parameters: {'n_estimators': 87, 'num_leaves': 30, 'max_depth': 9}. Best is trial 1 with value: 0.1309694932155369.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.029\n",
            "LGBM model\n",
            "  RMSE: 0.13660785695535804\n",
            "  MAE: 0.08945129908442498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:58,380]\u001b[0m Trial 7 finished with value: 0.13660785695535804 and parameters: {'n_estimators': 98, 'num_leaves': 33, 'max_depth': 8}. Best is trial 1 with value: 0.1309694932155369.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.040\n",
            "LGBM model\n",
            "  RMSE: 0.13395784018887136\n",
            "  MAE: 0.08791508105158806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:20:59,257]\u001b[0m Trial 8 finished with value: 0.13395784018887136 and parameters: {'n_estimators': 59, 'num_leaves': 28, 'max_depth': 8}. Best is trial 1 with value: 0.1309694932155369.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[01:20:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Prediction: 0.030\n",
            "LGBM model\n",
            "  RMSE: 0.1349349509209797\n",
            "  MAE: 0.08813694376349449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-17 01:21:00,203]\u001b[0m Trial 9 finished with value: 0.1349349509209797 and parameters: {'n_estimators': 72, 'num_leaves': 32, 'max_depth': 8}. Best is trial 1 with value: 0.1309694932155369.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q4uGa-Qm343"
      },
      "source": [
        "# Análise de melhor modelo de predicão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE_Pofz7uz1U",
        "outputId": "ffc347ac-f4af-4342-8afa-8882d00ee857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyngrok --quiet\n",
        "\n",
        "import mlflow\n",
        "\n",
        "with mlflow.start_run(run_name=\"MLflow on Colab\"):\n",
        "  mlflow.log_metric(\"m1\", 2.0)\n",
        "  mlflow.log_param(\"p1\", \"mlflow-colab\")\n",
        "\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\") # run tracking UI in the background\n",
        "\n",
        "\n",
        "# create remote tunnel using ngrok.com to allow local port access\n",
        "# borrowed from https://colab.research.google.com/github/alfozan/MLflow-GBRT-demo/blob/master/MLflow-GBRT-demo.ipynb#scrollTo=4h3bKHMYUIG6\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 36.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 184 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 225 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 245 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 266 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 276 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 286 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 409 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 430 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 440 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 450 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 460 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 471 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 481 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 491 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 501 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 522 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 532 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 542 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 552 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 563 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 573 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 583 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 614 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 624 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 634 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 645 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 655 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 665 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 686 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 696 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 706 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 716 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 727 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 737 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 746 kB 31.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "MLflow Tracking UI: https://01ca65a6a7cd.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}